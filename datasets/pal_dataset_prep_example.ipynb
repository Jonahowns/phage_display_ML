{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## First let's look at our dataset and determine how it should be split up"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "'/home/jonah/PycharmProjects/phage_display_ML/datasets'"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "## Let's make a directory within datasets to store all our files\n",
    "# Choose a short string 3-5 characters to denote this particular dataset\n",
    "# For this one, I chose \"pal\" for the rna aptamers of the PAL protein.\n",
    "# Make sure to set \"focus\" in datatype as the same string\n",
    "\n",
    "dataset_focus = \"pal\"\n",
    "dataset_dir = f\"./{dataset_focus}/\"\n",
    "\n",
    "if not os.path.isdir(dataset_dir):\n",
    "    os.mkdir(dataset_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Let's import our data_prep tools\n",
    "import data_prep as dp"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observed Characters: ['A', 'G', 'C', 'N', 'T']\n"
     ]
    }
   ],
   "source": [
    "# The below code can take awhile to run depending on the size of each file\n",
    "pal_df = dp.process_raw_fasta_files(\"r3.txt\", \"r5.txt\", \"r7.txt\", \"r8.txt\", \"r9.txt\", \"r10.txt\", \"r11.txt\", \"r12.txt\", \"r13.txt\", \"r14.txt\", \"r15.txt\", in_dir=\"/mnt/D1/rna_data_repo/PAL/\", out_dir=dataset_dir, violin_out=\"pal_data_lengths\", input_format=\"gunter\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "chars_to_remove = []\n",
    "# These all indicate some uncertainty as to the id of the bases. We could also replace these with a gap if we wanted to."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## Looking at the above graph + the length report in our out directory we see this"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 0 Repeat Sequences\r\n",
      "Length: 9 Number of Sequences 1\r\n",
      "Length: 35 Number of Sequences 1\r\n",
      "Length: 36 Number of Sequences 1\r\n",
      "Length: 37 Number of Sequences 77\r\n",
      "Length: 38 Number of Sequences 446\r\n",
      "Length: 39 Number of Sequences 45115\r\n",
      "Length: 40 Number of Sequences 1286475\r\n",
      "Length: 41 Number of Sequences 84851\r\n"
     ]
    }
   ],
   "source": [
    "!cat \"./pal/r12_len_report.txt\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## We see that the majority of data is length 40. But we can get more data by extending our range from length 39 to length 41. To make the data uniform in length, we will add gaps to the end of all sequences with lengths 39, 40"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "                                    sequence  length round  copy_num\n0   ACAGAAGCGTGGCAGGTCGACTTTCGAGAACGGTACCTCA      40   r15  127919.0\n1   CCATTCAGCAGCGAGCGGCGTAACTTGTCCTAACCTCAGC      40   r15   92244.0\n0   CGCTGAGTCAAGAAGTAGGCACACCGCGCTATCAAAGTCA      40   r11   88980.0\n0   CACGTTCAGAAGAGAGCGTTCCCATATCTCCACGTCCCTA      40   r12   67244.0\n1   ACAGTAGCGTGCCCATCGAGGCTCCCCGACCGGACCGTCA      40   r12   64848.0\n2   AGTTCAAAAGCGAGCTCCTCACTCCCTGAATTAGTGGTCC      40   r12   61208.0\n0   TCCTGTACGTGGCAGTTGCAGAAGCGCGACACCTACGAGA      40   r14   57362.0\n3   CATGTCTTGATTCTTTAGCAGAAAGGAAACCTACATGACA      40   r12   55923.0\n0   TCCTGTACGTGGCAGTTGCAGAAGCGCGACACCTACGAGA      40   r13   55800.0\n1   CCGAAGTATAGAAGCATGCTTGCCACGTTTTAACTCGTGG      40   r11   55129.0\n1   GTTCGTCCTGTGAGAGGCTGAAGCAGCTGCGGCCTCTCCG      40   r14   53459.0\n1   AAGACTCACAGAGTGTTAAGCAGACGCACTTTTGTGGACA      40   r13   48823.0\n2    ACCCTACCCTCCGGCGCGTTCAATGTGTAGCAGCACGCA      39   r14   46430.0\n2  CACAGTATAAAAGCATGCAGGTCTGTGATGGTACTCTCCCA      41   r11   45979.0\n4   GGTCATGCTTCAACTCGTTACAGTAGCGTTGACGAGGTGG      40   r12   44019.0\n3   TATCGTTAAGAAGGAGCGGTGAACGCGCGGGGTTCCACCA      40   r11   37554.0\n4   GCAGTATCTCGGCCACTGATCAAGCAGCTGGTGGATTGGC      40   r11   36024.0\n3   GACGATCCGACCAAGGTGCTTTAGAAGGAAGGCACCAGCA      40   r14   35234.0\n5   CAGGTATAGCAACATGCTTCCGCTTACTCTTCAAGGCTCA      40   r11   34745.0\n4  GCGGCCTACAGCAGCGATGCACCCAAACGGCGAGTTACTCA      41   r14   33778.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sequence</th>\n      <th>length</th>\n      <th>round</th>\n      <th>copy_num</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ACAGAAGCGTGGCAGGTCGACTTTCGAGAACGGTACCTCA</td>\n      <td>40</td>\n      <td>r15</td>\n      <td>127919.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>CCATTCAGCAGCGAGCGGCGTAACTTGTCCTAACCTCAGC</td>\n      <td>40</td>\n      <td>r15</td>\n      <td>92244.0</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>CGCTGAGTCAAGAAGTAGGCACACCGCGCTATCAAAGTCA</td>\n      <td>40</td>\n      <td>r11</td>\n      <td>88980.0</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>CACGTTCAGAAGAGAGCGTTCCCATATCTCCACGTCCCTA</td>\n      <td>40</td>\n      <td>r12</td>\n      <td>67244.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ACAGTAGCGTGCCCATCGAGGCTCCCCGACCGGACCGTCA</td>\n      <td>40</td>\n      <td>r12</td>\n      <td>64848.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>AGTTCAAAAGCGAGCTCCTCACTCCCTGAATTAGTGGTCC</td>\n      <td>40</td>\n      <td>r12</td>\n      <td>61208.0</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>TCCTGTACGTGGCAGTTGCAGAAGCGCGACACCTACGAGA</td>\n      <td>40</td>\n      <td>r14</td>\n      <td>57362.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>CATGTCTTGATTCTTTAGCAGAAAGGAAACCTACATGACA</td>\n      <td>40</td>\n      <td>r12</td>\n      <td>55923.0</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>TCCTGTACGTGGCAGTTGCAGAAGCGCGACACCTACGAGA</td>\n      <td>40</td>\n      <td>r13</td>\n      <td>55800.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>CCGAAGTATAGAAGCATGCTTGCCACGTTTTAACTCGTGG</td>\n      <td>40</td>\n      <td>r11</td>\n      <td>55129.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>GTTCGTCCTGTGAGAGGCTGAAGCAGCTGCGGCCTCTCCG</td>\n      <td>40</td>\n      <td>r14</td>\n      <td>53459.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>AAGACTCACAGAGTGTTAAGCAGACGCACTTTTGTGGACA</td>\n      <td>40</td>\n      <td>r13</td>\n      <td>48823.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ACCCTACCCTCCGGCGCGTTCAATGTGTAGCAGCACGCA</td>\n      <td>39</td>\n      <td>r14</td>\n      <td>46430.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>CACAGTATAAAAGCATGCAGGTCTGTGATGGTACTCTCCCA</td>\n      <td>41</td>\n      <td>r11</td>\n      <td>45979.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>GGTCATGCTTCAACTCGTTACAGTAGCGTTGACGAGGTGG</td>\n      <td>40</td>\n      <td>r12</td>\n      <td>44019.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>TATCGTTAAGAAGGAGCGGTGAACGCGCGGGGTTCCACCA</td>\n      <td>40</td>\n      <td>r11</td>\n      <td>37554.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>GCAGTATCTCGGCCACTGATCAAGCAGCTGGTGGATTGGC</td>\n      <td>40</td>\n      <td>r11</td>\n      <td>36024.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>GACGATCCGACCAAGGTGCTTTAGAAGGAAGGCACCAGCA</td>\n      <td>40</td>\n      <td>r14</td>\n      <td>35234.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>CAGGTATAGCAACATGCTTCCGCTTACTCTTCAAGGCTCA</td>\n      <td>40</td>\n      <td>r11</td>\n      <td>34745.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>GCGGCCTACAGCAGCGATGCACCCAAACGGCGAGTTACTCA</td>\n      <td>41</td>\n      <td>r14</td>\n      <td>33778.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pal_df.sort_values(\"copy_num\", ascending=False).head(20)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "array(['sequence', 'length', 'round', 'copy_num'], dtype=object)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thc_df.columns.values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# So now we can define our datatype\n",
    "\n",
    "# Datatype defines the basics of our data, Each datatype is specified for a group of related fasta files\n",
    "# Focus - > short string specifier that gives the overall dataset we are using\n",
    "# Molecule -> What kind of sequence data? currently protein, dna, and rna are supported\n",
    "# id -> short string specifier ONLY for datasets which have different clustering methods (CLUSTERS ONLY)\n",
    "# process -> How were the gaps added to each dataset, used to name directory (CLUSTERS ONLY)\n",
    "# clusters -> How many clusters are in each data file (1 if no clusters)\n",
    "# cluster_indices -> Define the lengths of data put in each cluster, It is inclusive so [12, 16] includes length 12 and length 16. There must be cluster_indices for each cluster\n",
    "# gap_position_indices -> Index where gaps should be added to each sequence that is short of the maximum length. (-1 means add gaps to the end of the clusters)\n",
    "\n",
    "pal_datatype = {\"focus\": \"pal\", \"molecule\": \"rna\", \"id\": None, \"process\": None, \"clusters\": 1, \"gap_position_indices\": [-1], \"cluster_indices\": [[39, 41]]}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Before we do anything else, we need to copy our datatype to phage_display_ML/rbm_torch/analysis/global_info.py\n",
    "## Also make sure to add the new datatype to the datatype_list in the same file."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Next we need to process the raw files and make our own fasta files with our preferred formatting"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'datasets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-11-f1e16892701e>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mimportlib\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0mimportlib\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreload\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdatasets\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdata_prep\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m: name 'datasets' is not defined"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(datasets.data_prep)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# chars_to_remove = [\"W\", \"D\", \"V\", \"M\", \"B\", \"R\", \"K\", \"Y\", \"H\", \"S\"]\n",
    "# chars_replace = {x: \"-\" for x in chars_to_remove}\n",
    "dp.prepare_data_files(\"pal\", pal_df, target_dir=dataset_dir, character_conversion={\"T\": \"U\", \"N\":\"-\"}, remove_chars=None) # Creates datafiles in target directory"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Now we have generated data files that we can use for training our RBM or CRBM"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# lets double check if only contains characters we know\n",
    "# seqs, chars = dp.fasta_read(dataset_dir+\"rfam.fasta\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C', 'G', '-', 'A', 'U']\n"
     ]
    }
   ],
   "source": [
    "# print(chars)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">seq0-144.0\r\n",
      "UAUUUUACAGUGCGACUACCGUCCGGCUAAGCAACGGCCA-\r\n",
      ">seq1-100.0\r\n",
      "GUACGAGGGUGGCAGAAGCGCGAUCCACGCUUAAGCAUCA-\r\n",
      ">seq2-6.0\r\n",
      "CGCGAACGUGGCAAGCAGAUGCCAUCCAACCGUGUACUCCA\r\n",
      ">seq3-5.0\r\n",
      "CGAGGAGGGGGUUCAGCCCGGUGAGCACAAUCCGUGGGGU-\r\n",
      ">seq4-4.0\r\n",
      "UCUCUGGGGCAUACGGAGAGGCCCGGUAUAAGCGGUCAAG-\r\n",
      ">seq5-4.0\r\n",
      "CCUAAAGCAGCUUAGGUGCAUGCGCACCUCUGGAAUCGUC-\r\n",
      ">seq6-4.0\r\n",
      "CAGUUCCGGUCCUGGAUGUGUCCUUCGGACGAGUCAAGCA-\r\n",
      ">seq7-4.0\r\n",
      "GGAUUCAGUCACAAGUCCCGGUAGCUCCUCUGGGCAUUAG-\r\n",
      ">seq8-4.0\r\n",
      "CCCUUCUACAUGACCCUGCCCCCCGCGGGGCCGAUAGCGA-\r\n",
      ">seq9-3.0\r\n",
      "CCGCAAGCCCCGUCGGGAUUUGCAC-CUAGCGACUUGGAG-\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 20 \"./pal/r3.fasta\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Our Last Step is to generate a dataset file, which will inform our models about the location of the data as well as other important details"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "sys.path.append(\"../\")\n",
    "import rbm_torch.analysis.global_info as gi"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "'/home/jonah/PycharmProjects/phage_display_ML/datasets'"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "gi.generate_dataset_file([\"r3.fasta\", \"r5.fasta\", \"r7.fasta\", \"r8.fasta\", \"r9.fasta\", \"r10.fasta\", \"r11.fasta\", \"r12.fasta\", \"r13.fasta\", \"r14.fasta\", \"r15.fasta\", \"r16.fasta\"], gi.supported_datatypes[\"pal\"], destination=\"./dataset_files/\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"data_files\": {\"1\": [\"r3.fasta\", \"r5.fasta\", \"r7.fasta\", \"r8.fasta\", \"r9.fasta\", \"r10.fasta\", \"r11.fasta\", \"r12.fasta\", \"r13.fasta\", \"r14.fasta\", \"r15.fasta\", \"r16.fasta\"]}, \"rounds\": {\"1\": [\"r3\", \"r5\", \"r7\", \"r8\", \"r9\", \"r10\", \"r11\", \"r12\", \"r13\", \"r14\", \"r15\", \"r16\"]}, \"model_names\": {\"weights\": {\"1\": [\"r3_w\", \"r5_w\", \"r7_w\", \"r8_w\", \"r9_w\", \"r10_w\", \"r11_w\", \"r12_w\", \"r13_w\", \"r14_w\", \"r15_w\", \"r16_w\"]}, \"equal\": {\"1\": [\"r3\", \"r5\", \"r7\", \"r8\", \"r9\", \"r10\", \"r11\", \"r12\", \"r13\", \"r14\", \"r15\", \"r16\"]}}, \"local_model_dir\": {\"rbm\": \"/mnt/D1/globus/pig_trained_rbms/None\", \"crbm\": \"/mnt/D1/globus/pig_trained_crbms/None\"}, \"data_dir\": \"../../datasets/thc/\", \"server_model_dir\": {\"rbm\": \"datasets/thc/trained_rbms/\", \"crbm\": \"datasets/thc/trained_crbms/\"}, \"molecule\": \"rna\", \"configkey\": {\"1\": \"thc\"}, \"clusters\": 1}"
     ]
    }
   ],
   "source": [
    "!cat \"./dataset_files/thc.json\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# We're all set to run our models now, except for creating default configs for each dataset\n",
    "# Here is an example one for crbm. It should be appended to crbm_configs.py and added to all_configs\n",
    "\n",
    "pal_default_config = {\"fasta_file\": \"\",\n",
    "          \"v_num\": 43,\n",
    "          \"q\": 5,\n",
    "          \"molecule\": \"rna\",\n",
    "          \"epochs\": 100, # get's overwritten by training script anyway\n",
    "          \"seed\": seed, # this is defined in the config file\n",
    "          \"batch_size\": 10000, # can be raised or lowered depending on memory usage\n",
    "          \"mc_moves\": 4,\n",
    "          \"lr\": 0.006,\n",
    "          \"lr_final\": None, # automatically set as lr * 1e-2\n",
    "          \"decay_after\": 0.75,\n",
    "          \"loss_type\": \"free_energy\",\n",
    "          \"sample_type\": \"gibbs\",\n",
    "          \"sequence_weights\": None,\n",
    "          \"optimizer\": \"AdamW\",\n",
    "          \"weight_decay\": 0.001,  # l2 norm on all parameters\n",
    "          \"l1_2\": 25.0,\n",
    "          \"lf\": 5.0,\n",
    "          \"ld\": 10.0,\n",
    "          \"data_worker_num\": 4\n",
    "          }\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding Whole Convolutions for Input with 43 inputs:\n",
      "Whole Convolution Found: Kernel: 1, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 1, Stride: 2, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 1, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 1, Stride: 2, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 1, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 1, Stride: 2, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 2, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 2, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 2, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 3, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 3, Stride: 2, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 3, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 3, Stride: 2, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 3, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 3, Stride: 2, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 4, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 4, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 4, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 5, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 5, Stride: 2, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 5, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 5, Stride: 2, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 5, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 5, Stride: 2, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 6, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 6, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 6, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 7, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 7, Stride: 2, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 7, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 7, Stride: 2, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 7, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 7, Stride: 2, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 8, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 8, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 8, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 9, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 9, Stride: 2, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 9, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 9, Stride: 2, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 9, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 9, Stride: 2, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 10, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 10, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 10, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 11, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 11, Stride: 2, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 11, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 11, Stride: 2, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 11, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 11, Stride: 2, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 12, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 12, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 12, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 13, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 13, Stride: 2, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 13, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 13, Stride: 2, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 13, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 13, Stride: 2, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 14, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 14, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 14, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 15, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 15, Stride: 2, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 15, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 15, Stride: 2, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 15, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 15, Stride: 2, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 16, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 16, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 16, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 17, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 17, Stride: 2, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 17, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 17, Stride: 2, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 17, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 17, Stride: 2, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 18, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 18, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 18, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 19, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 19, Stride: 2, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 19, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 19, Stride: 2, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 19, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 19, Stride: 2, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 20, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 20, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 20, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 21, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 21, Stride: 2, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 21, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 21, Stride: 2, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 21, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 21, Stride: 2, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 22, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 22, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 22, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 23, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 23, Stride: 2, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 23, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 23, Stride: 2, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 23, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 23, Stride: 2, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 24, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 24, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 24, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 25, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 25, Stride: 2, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 25, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 25, Stride: 2, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 25, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 25, Stride: 2, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 26, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 26, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 26, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 27, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 27, Stride: 2, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 27, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 27, Stride: 2, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 27, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 27, Stride: 2, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 28, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 28, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 28, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 29, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 29, Stride: 2, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 29, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 29, Stride: 2, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 29, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 29, Stride: 2, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 30, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 30, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 30, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 31, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 31, Stride: 2, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 31, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 31, Stride: 2, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 31, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 31, Stride: 2, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 32, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 32, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 32, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 33, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 33, Stride: 2, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 33, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 33, Stride: 2, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 33, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 33, Stride: 2, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 34, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 34, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 34, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 35, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 35, Stride: 2, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 35, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 35, Stride: 2, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 35, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 35, Stride: 2, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 36, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 36, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 36, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 37, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 37, Stride: 2, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 37, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 37, Stride: 2, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 37, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 37, Stride: 2, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 38, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 38, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 38, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 39, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 39, Stride: 2, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 39, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 39, Stride: 2, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 39, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 39, Stride: 2, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 40, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 40, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 40, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 41, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 41, Stride: 2, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 41, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 41, Stride: 2, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 41, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 41, Stride: 2, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 42, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 42, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 42, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 43, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 43, Stride: 2, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 43, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 43, Stride: 2, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 43, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 43, Stride: 2, Dilation: 1, Padding: 2\n"
     ]
    }
   ],
   "source": [
    "# TO figure out the convolution topology we use some helper functions in crbm.py\n",
    "\n",
    "# This function gives all convolutions that fully sample all visible units on the conv transpose for a given data size\n",
    "from rbm_torch.utils import suggest_conv_size\n",
    "\n",
    "# one hot encoded vector of input size (B x V X Q) is the input the CRBM uses\n",
    "visible_num = 43 # V\n",
    "q_states = 5 #Q\n",
    "input_shape = (visible_num, q_states)\n",
    "suggest_conv_size(input_shape, padding_max=2, dilation_max=1, stride_max=2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## My current line of thinking is that having a dilation > 1 or a stride > 1 will introduce some position specific effects."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## Idea: The size of the kernel controls defines the size of the motif/pattern of the convolutional filter. So for this dataset I expect long filters to capture the secondary structure of this rfam family\n",
    "\n",
    "# It is possible to use different strides and dilations, but I think they only take away from the interpretability of the convolutional filters. Also, they can lead to unsampled visible units on the convolution transpose. Likewise using a hidden layer with the kernel size the same as the number of visible units is somewhat equivalent to an RBM if not exactly (I haven't verified). This introduces a positional dependence into the corresponding hidden layer of the model.\n",
    "\n",
    "# So I will use sizes:  11, 25, 46, 86, 100, 112\n",
    "# Motif Finding:  Local Features-------Global Features\n",
    "# Names/Keys for hidden layers in the convolutional topology can be named anything you can use as key in a dictionary\n",
    "# Model outputs are the average of each hidden layer with a set weight\n",
    "pal_default_config[\"convolution_topology\"] = {\"hidden10\": {\"number\": 15, \"kernel\": (9, pal_default_config[\"q\"]), \"stride\": (1, 1), \"padding\": (0, 0), \"dilation\": (1, 1), \"output_padding\": (0, 0), \"weight\": 1.0},\n",
    "                                            \"hidden25\": {\"number\": 15, \"kernel\": (17, pal_default_config[\"q\"]), \"stride\": (1, 1), \"padding\": (0, 0), \"dilation\": (1, 1), \"output_padding\": (0, 0), \"weight\": 1.0},\n",
    "                                            \"hidden46\": {\"number\": 15, \"kernel\": (25, pal_default_config[\"q\"]), \"stride\": (1, 1), \"padding\": (0, 0), \"dilation\": (1, 1), \"output_padding\": (0, 0), \"weight\": 1.0},\n",
    "                                            \"hidden86\": {\"number\": 15, \"kernel\": (33, pal_default_config[\"q\"]), \"stride\": (1, 1), \"padding\": (0, 0), \"dilation\": (1, 1), \"output_padding\": (0, 0), \"weight\": 1.0},\n",
    "                                             }"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### COPY THE ABOVE CELL TO CRBM CONFIGS AS WELL"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Lets create a submission script for a slurm system to run by using the script submit.py\n",
    "\n",
    "# Submission files are stored in rbm_torch/submission/\n",
    "\n",
    "# From Directory rbm_torch I ran\n",
    "\"python submit.py -d ribo -r all -p wzhengpu1 -q wildfire -m crbm -e 200 -g 2 --precision double\"\n",
    "\n",
    "# Use python submit.py -h for help!"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "utils",
   "language": "python",
   "display_name": "utils"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}