{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## First let's look at our dataset and determine how it should be split up"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "'/home/jonah/PycharmProjects/phage_display_ML/datasets'"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "## Let's make a directory within datasets to store all our files\n",
    "# Choose a short string 3-5 characters to denote this particular dataset\n",
    "# For this one, I chose \"ribo\" for the ribosomal rna.\n",
    "# Make sure to set \"focus\" in datatype as the same string\n",
    "\n",
    "dataset_focus = \"cov\"\n",
    "dataset_dir = f\"./{dataset_focus}/\"\n",
    "\n",
    "if not os.path.isdir(dataset_dir):\n",
    "    os.mkdir(dataset_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Let's import our data_prep tools\n",
    "import data_prep as dp"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observed Characters: ['C', 'A', 'N', 'G', 'T']\n"
     ]
    }
   ],
   "source": [
    "# The below code can take awhile to run depending on the size of each file\n",
    "cov_df = dp.process_raw_fasta_files(\"r1.txt\", \"r2.txt\", \"r3.txt\", \"r4.txt\", \"r5.txt\", \"r6.txt\", \"r7.txt\", \"r8.txt\", \"r9.txt\", \"r10.txt\", \"r11.txt\", \"r12.txt\", in_dir=\"/mnt/D1/sars-cov-2-data/processed/\", out_dir=dataset_dir, violin_out=\"cov_data_lengths\", input_format=\"fasta\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Looking at the above graph + the length report in our out directory we see this\n",
    "\n",
    "<img src=\"./cov/cov_data_lengths.png\" alt=\"COV Data Lengths\" style=\"height: 50px; width:50px;\"/>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 3036794 Repeat Sequences\r\n",
      "Length: 19 Number of Sequences 1\r\n",
      "Length: 25 Number of Sequences 2\r\n",
      "Length: 27 Number of Sequences 2\r\n",
      "Length: 28 Number of Sequences 2\r\n",
      "Length: 29 Number of Sequences 6\r\n",
      "Length: 30 Number of Sequences 29\r\n",
      "Length: 31 Number of Sequences 59\r\n",
      "Length: 32 Number of Sequences 74\r\n",
      "Length: 33 Number of Sequences 108\r\n",
      "Length: 34 Number of Sequences 125\r\n",
      "Length: 35 Number of Sequences 286\r\n",
      "Length: 36 Number of Sequences 546\r\n",
      "Length: 37 Number of Sequences 1280\r\n",
      "Length: 38 Number of Sequences 5464\r\n",
      "Length: 39 Number of Sequences 12615\r\n",
      "Length: 40 Number of Sequences 2078863\r\n",
      "Length: 41 Number of Sequences 162432\r\n"
     ]
    }
   ],
   "source": [
    "!cat ./cov/r5_len_report.txt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# So now we can define our datatype\n",
    "\n",
    "# Datatype defines the basics of our data, Each datatype is specified for a group of related fasta files\n",
    "# Focus - > short string specifier that gives the overall dataset we are using\n",
    "# Molecule -> What kind of sequence data? currently protein, dna, and rna are supported\n",
    "# id -> short string specifier ONLY for datasets which have different clustering methods (CLUSTERS ONLY)\n",
    "# process -> How were the gaps added to each dataset, used to name directory (CLUSTERS ONLY)\n",
    "# clusters -> How many clusters are in each data file (1 if no clusters)\n",
    "# cluster_indices -> Define the lengths of data put in each cluster, It is inclusive so [12, 16] includes length 12 and length 16. There must be cluster_indices for each cluster\n",
    "# gap_position_indices -> Index where gaps should be added to each sequence that is short of the maximum length. (-1 means add gaps to the end of the clusters)\n",
    "\n",
    "cov_datatype = {\"focus\": \"cov\", \"molecule\": \"dna\", \"id\": None, \"process\": None, \"clusters\": 1, \"gap_position_indices\": [-1], \"cluster_indices\": [[40, 40]]}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Before we do anything else, we need to copy our datatype to phage_display_ML/rbm_torch/global_info.py\n",
    "## Also make sure to add the new datatype to the datatype_list in the same file."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Next we need to process the raw files and make our own fasta files with our preferred formatting"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# chars_to_remove = [\"W\", \"D\", \"V\", \"M\", \"B\", \"R\", \"K\", \"Y\", \"H\", \"S\"]\n",
    "# chars_replace = {x: \"-\" for x in chars_to_remove}\n",
    "dp.prepare_data_files(\"cov\", cov_df, target_dir=dataset_dir, character_conversion={\"T\": \"U\", \"N\":\"-\"}, remove_chars=None) # Creates datafiles in target directory"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Now we have generated a data file that we can use for training our RBM or CRBM"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#We will also try scaling the weights based off other information. In this case I am going choose a weight that is representative of both the copy number and the number of sequences that match with less than a threshold of difference b/t one another. To do this I'm going to read in the already processed files with their count number. And write them out with the altered weights in the fasta file"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### The Below Scaling Weights didn't work too well, returned about the same model as just the raw weights"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## Scaling all Rounds except R1 and R2 (way too much data, pairwise neighbor jobs aren't done yet)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process Time 0.587090015411377\n"
     ]
    }
   ],
   "source": [
    "fasta_file = \"r3.fasta\"\n",
    "dp.scale_weights(f\"./cov/{fasta_file}\", \"./cov/sw/\", f\"./cov/{fasta_file}_15_neighbor_counts.pkl\", molecule=\"dna\", threads=12, precision=20, scale_log=True, copynum_coeff=5.0, neighbor_coeff=0.5, normalize_threshold=0.75)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "sys.path.append(\"../rbm_torch/\")\n",
    "import rbm_torch.utils as utils\n",
    "import data_prep as dp\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process Time 0.5592570304870605\n",
      "Process Time 0.3178377151489258\n",
      "Process Time 1.5709872245788574\n",
      "Process Time 1.1642749309539795\n",
      "Process Time 2.1850874423980713\n",
      "Process Time 0.6264688968658447\n",
      "Process Time 0.16741061210632324\n",
      "Process Time 0.41866111755371094\n",
      "Process Time 0.20952653884887695\n",
      "Process Time 0.4487771987915039\n"
     ]
    }
   ],
   "source": [
    "all_fasta_files = [f\"r{i}.fasta\" for i in range(3, 13)]\n",
    "all_affinities =[]\n",
    "min_vals = []\n",
    "for fasta_file in all_fasta_files:\n",
    "    seqs, affs, chars, q = utils.fasta_read(f\"./cov/{fasta_file}\", \"dna\", threads=12)\n",
    "    # stand_affs = dp.standardize_affinities(affs, out_plot=f\"./cov/sw/{fasta_file.split('.')[0]}_stand_affs\")\n",
    "    stand_affs = dp.standardize_affinities(affs, out_plot=f\"./cov/nw/{fasta_file.split('.')[0]}_stand_affs\")\n",
    "    min_vals.append(min(stand_affs))\n",
    "    all_affinities.append(stand_affs)\n",
    "    # neighs = dp.load_neighbor_file(f\"./cov/{fasta_file}_15_neighbor_counts.pkl\")\n",
    "    # neighs_log_scaled = dp.scale_values_np(dp.log_scale(neighs, base=0.001), min=0.01, max=1.00)\n",
    "    # dp.quick_hist(neighs_log_scaled.squeeze(1).tolist(), outfile=f\"./cov/sw/{fasta_file.split('.')[0]}_neighs_log_scaled\")\n",
    "    # new_weights = np.asarray(stand_affs) * neighs_log_scaled.squeeze(1)\n",
    "    # dp.quick_hist(new_weights.tolist(), outfile=f\"./cov/sw/{fasta_file.split('.')[0]}_aff_and_neigh_weights\")\n",
    "    # dp.make_weight_file(f\"./cov/nw/{fasta_file.split('.')[0]}_nw_weights\", stand_affs, \"nw\")\n",
    "    # dp.write_fasta(seqs, stand_affs, f\"./cov/nw/{fasta_file}\")\n",
    "    # dp.write_fasta(seqs, new_weights.tolist(), f\"./cov/sw/{fasta_file.split('.')[0]}_n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "thresholds = min_vals\n",
    "for fid, fasta_file in enumerate(all_fasta_files):\n",
    "    new_weights =dp.negate_affinites(all_affinities[fid], thresholds[fid], out_plot=f\"./cov/nw/{fasta_file.split('.')[0]}_n3_affs\", negative_factor=10000.)\n",
    "    dp.make_weight_file(f\"./cov/nw/{fasta_file.split('.')[0]}_n3_weights\", new_weights, \"n3\")\n",
    "    # dp.write_fasta(seqs, stand_affs, f\"./cov/nw/{fasta_file}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.006617928672809606 % done\n",
      "0.013235857345619212 % done\n",
      "0.01985378601842882 % done\n",
      "0.026471714691238424 % done\n",
      "0.03308964336404803 % done\n",
      "0.03970757203685764 % done\n",
      "0.04632550070966725 % done\n",
      "0.05294342938247685 % done\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-82-70592f7fbe35>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mneighs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcalc_neighbors\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mthreshold\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0.15\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m<ipython-input-81-9e68a33907ca>\u001B[0m in \u001B[0;36mcalc_neighbors\u001B[0;34m(X, threshold)\u001B[0m\n\u001B[1;32m     11\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     12\u001B[0m     \u001B[0mneighbors\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 13\u001B[0;31m     \u001B[0;32mfor\u001B[0m \u001B[0mx\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mgen\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     14\u001B[0m         \u001B[0mneighbors\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     15\u001B[0m         \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mneighbors\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m/\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m*\u001B[0m \u001B[0;36m100\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"% done\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/utils/lib/python3.8/site-packages/sklearn/metrics/pairwise.py\u001B[0m in \u001B[0;36mpairwise_distances_chunked\u001B[0;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001B[0m\n\u001B[1;32m   1621\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1622\u001B[0m             \u001B[0mX_chunk\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mX\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0msl\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1623\u001B[0;31m         D_chunk = pairwise_distances(X_chunk, Y, metric=metric,\n\u001B[0m\u001B[1;32m   1624\u001B[0m                                      n_jobs=n_jobs, **kwds)\n\u001B[1;32m   1625\u001B[0m         if ((X is Y or Y is None)\n",
      "\u001B[0;32m~/anaconda3/envs/utils/lib/python3.8/site-packages/sklearn/utils/validation.py\u001B[0m in \u001B[0;36minner_f\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     61\u001B[0m             \u001B[0mextra_args\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mall_args\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     62\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mextra_args\u001B[0m \u001B[0;34m<=\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 63\u001B[0;31m                 \u001B[0;32mreturn\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     64\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     65\u001B[0m             \u001B[0;31m# extra_args > 0\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/utils/lib/python3.8/site-packages/sklearn/metrics/pairwise.py\u001B[0m in \u001B[0;36mpairwise_distances\u001B[0;34m(X, Y, metric, n_jobs, force_all_finite, **kwds)\u001B[0m\n\u001B[1;32m   1776\u001B[0m             \u001B[0mwarnings\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwarn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmsg\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mDataConversionWarning\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1777\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1778\u001B[0;31m         X, Y = check_pairwise_arrays(X, Y, dtype=dtype,\n\u001B[0m\u001B[1;32m   1779\u001B[0m                                      force_all_finite=force_all_finite)\n\u001B[1;32m   1780\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/utils/lib/python3.8/site-packages/sklearn/utils/validation.py\u001B[0m in \u001B[0;36minner_f\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     61\u001B[0m             \u001B[0mextra_args\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mall_args\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     62\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mextra_args\u001B[0m \u001B[0;34m<=\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 63\u001B[0;31m                 \u001B[0;32mreturn\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     64\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     65\u001B[0m             \u001B[0;31m# extra_args > 0\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/utils/lib/python3.8/site-packages/sklearn/metrics/pairwise.py\u001B[0m in \u001B[0;36mcheck_pairwise_arrays\u001B[0;34m(X, Y, precomputed, dtype, accept_sparse, force_all_finite, copy)\u001B[0m\n\u001B[1;32m    147\u001B[0m                         \u001B[0mcopy\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mcopy\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mforce_all_finite\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mforce_all_finite\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    148\u001B[0m                         estimator=estimator)\n\u001B[0;32m--> 149\u001B[0;31m         Y = check_array(Y, accept_sparse=accept_sparse, dtype=dtype,\n\u001B[0m\u001B[1;32m    150\u001B[0m                         \u001B[0mcopy\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mcopy\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mforce_all_finite\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mforce_all_finite\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    151\u001B[0m                         estimator=estimator)\n",
      "\u001B[0;32m~/anaconda3/envs/utils/lib/python3.8/site-packages/sklearn/utils/validation.py\u001B[0m in \u001B[0;36minner_f\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     61\u001B[0m             \u001B[0mextra_args\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mall_args\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     62\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mextra_args\u001B[0m \u001B[0;34m<=\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 63\u001B[0;31m                 \u001B[0;32mreturn\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     64\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     65\u001B[0m             \u001B[0;31m# extra_args > 0\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/utils/lib/python3.8/site-packages/sklearn/utils/validation.py\u001B[0m in \u001B[0;36mcheck_array\u001B[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001B[0m\n\u001B[1;32m    671\u001B[0m                     \u001B[0marray\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0marray\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mastype\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcasting\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"unsafe\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcopy\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    672\u001B[0m                 \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 673\u001B[0;31m                     \u001B[0marray\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0masarray\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0marray\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0morder\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0morder\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    674\u001B[0m             \u001B[0;32mexcept\u001B[0m \u001B[0mComplexWarning\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mcomplex_warning\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    675\u001B[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001B[0;32m~/anaconda3/envs/utils/lib/python3.8/site-packages/numpy/core/_asarray.py\u001B[0m in \u001B[0;36masarray\u001B[0;34m(a, dtype, order)\u001B[0m\n\u001B[1;32m     81\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     82\u001B[0m     \"\"\"\n\u001B[0;32m---> 83\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0marray\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0ma\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcopy\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0morder\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0morder\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     84\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     85\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "neighs = calc_neighbors(X, threshold=0.15)\n",
    "o = open(f\"{fasta_file}_pairwise_distances.txt\", \"w+\")\n",
    "o.write(neighs)\n",
    "o.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "sys.path.append(\"../\")\n",
    "import rbm_torch.global_info as gi"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "'/home/jonah/PycharmProjects/phage_display_ML/datasets'"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "gi.generate_dataset_file([f\"r{i}.fasta\" for i in range(1, 13)], gi.supported_datatypes[\"cov\"], destination=\"./dataset_files/\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"data_files\": {\"1\": [\"r1.fasta\", \"r2.fasta\", \"r3.fasta\", \"r4.fasta\", \"r5.fasta\", \"r6.fasta\", \"r7.fasta\", \"r8.fasta\", \"r9.fasta\", \"r10.fasta\", \"r11.fasta\", \"r12.fasta\"]}, \"rounds\": {\"1\": [\"r1\", \"r2\", \"r3\", \"r4\", \"r5\", \"r6\", \"r7\", \"r8\", \"r9\", \"r10\", \"r11\", \"r12\"]}, \"model_names\": {\"1\": [\"r1\", \"r2\", \"r3\", \"r4\", \"r5\", \"r6\", \"r7\", \"r8\", \"r9\", \"r10\", \"r11\", \"r12\"]}, \"local_model_dir\": {\"rbm\": \"/mnt/D1/globus/cov_trained_rbms/\", \"crbm\": \"/mnt/D1/globus/cov_trained_crbms/\"}, \"data_dir\": \"../../datasets/cov/\", \"server_model_dir\": {\"rbm\": \"datasets/cov/trained_rbms/\", \"crbm\": \"datasets/cov/trained_crbms/\"}, \"molecule\": \"dna\", \"configkey\": {\"1\": \"cov\"}, \"clusters\": 1}"
     ]
    }
   ],
   "source": [
    "!cat \"./dataset_files/cov.json\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# We're all set to run our models now, except for creating default configs for each dataset\n",
    "# Here is an example one for crbm. It should be appended to crbm_configs.py and added to all_configs dictionary also in crbm_configs.py\n",
    "\n",
    "thc_default_config = {\"fasta_file\": \"\",\n",
    "          \"v_num\": 43,\n",
    "          \"q\": 5,\n",
    "          \"molecule\": \"rna\",\n",
    "          \"epochs\": 100, # get's overwritten by training script anyway\n",
    "          \"seed\": seed, # this is defined in the config file\n",
    "          \"batch_size\": 10000, # can be raised or lowered depending on memory usage\n",
    "          \"mc_moves\": 4,\n",
    "          \"lr\": 0.006,\n",
    "          \"lr_final\": None, # automatically set as lr * 1e-2\n",
    "          \"decay_after\": 0.75,\n",
    "          \"loss_type\": \"free_energy\",\n",
    "          \"sample_type\": \"gibbs\",\n",
    "          \"sequence_weights\": None,\n",
    "          \"optimizer\": \"AdamW\",\n",
    "          \"weight_decay\": 0.001,  # l2 norm on all parameters\n",
    "          \"l1_2\": 25.0,\n",
    "          \"lf\": 5.0,\n",
    "          \"ld\": 10.0,\n",
    "          \"data_worker_num\": 4\n",
    "          }\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding Whole Convolutions for Input with 43 inputs:\n",
      "Whole Convolution Found: Kernel: 1, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 1, Stride: 2, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 1, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 1, Stride: 2, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 1, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 1, Stride: 2, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 2, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 2, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 2, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 3, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 3, Stride: 2, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 3, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 3, Stride: 2, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 3, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 3, Stride: 2, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 4, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 4, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 4, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 5, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 5, Stride: 2, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 5, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 5, Stride: 2, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 5, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 5, Stride: 2, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 6, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 6, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 6, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 7, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 7, Stride: 2, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 7, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 7, Stride: 2, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 7, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 7, Stride: 2, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 8, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 8, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 8, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 9, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 9, Stride: 2, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 9, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 9, Stride: 2, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 9, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 9, Stride: 2, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 10, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 10, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 10, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 11, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 11, Stride: 2, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 11, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 11, Stride: 2, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 11, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 11, Stride: 2, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 12, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 12, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 12, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 13, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 13, Stride: 2, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 13, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 13, Stride: 2, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 13, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 13, Stride: 2, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 14, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 14, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 14, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 15, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 15, Stride: 2, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 15, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 15, Stride: 2, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 15, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 15, Stride: 2, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 16, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 16, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 16, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 17, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 17, Stride: 2, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 17, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 17, Stride: 2, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 17, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 17, Stride: 2, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 18, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 18, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 18, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 19, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 19, Stride: 2, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 19, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 19, Stride: 2, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 19, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 19, Stride: 2, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 20, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 20, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 20, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 21, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 21, Stride: 2, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 21, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 21, Stride: 2, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 21, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 21, Stride: 2, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 22, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 22, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 22, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 23, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 23, Stride: 2, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 23, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 23, Stride: 2, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 23, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 23, Stride: 2, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 24, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 24, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 24, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 25, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 25, Stride: 2, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 25, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 25, Stride: 2, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 25, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 25, Stride: 2, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 26, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 26, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 26, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 27, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 27, Stride: 2, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 27, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 27, Stride: 2, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 27, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 27, Stride: 2, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 28, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 28, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 28, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 29, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 29, Stride: 2, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 29, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 29, Stride: 2, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 29, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 29, Stride: 2, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 30, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 30, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 30, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 31, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 31, Stride: 2, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 31, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 31, Stride: 2, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 31, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 31, Stride: 2, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 32, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 32, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 32, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 33, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 33, Stride: 2, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 33, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 33, Stride: 2, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 33, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 33, Stride: 2, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 34, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 34, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 34, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 35, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 35, Stride: 2, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 35, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 35, Stride: 2, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 35, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 35, Stride: 2, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 36, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 36, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 36, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 37, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 37, Stride: 2, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 37, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 37, Stride: 2, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 37, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 37, Stride: 2, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 38, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 38, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 38, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 39, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 39, Stride: 2, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 39, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 39, Stride: 2, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 39, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 39, Stride: 2, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 40, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 40, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 40, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 41, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 41, Stride: 2, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 41, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 41, Stride: 2, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 41, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 41, Stride: 2, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 42, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 42, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 42, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 43, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 43, Stride: 2, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 43, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 43, Stride: 2, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 43, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 43, Stride: 2, Dilation: 1, Padding: 2\n"
     ]
    }
   ],
   "source": [
    "# TO figure out the convolution topology we use some helper functions in crbm.py\n",
    "\n",
    "# This function gives all convolutions that fully sample all visible units on the conv transpose for a given data size\n",
    "from rbm_torch.utils import suggest_conv_size\n",
    "\n",
    "# one hot encoded vector of input size (B x V X Q) is the input the CRBM uses\n",
    "visible_num = 43 # V\n",
    "q_states = 5 #Q\n",
    "input_shape = (visible_num, q_states)\n",
    "suggest_conv_size(input_shape, padding_max=2, dilation_max=1, stride_max=2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## My current line of thinking is that having a dilation > 1 or a stride > 1 will introduce some position specific effects."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## Idea: The size of the kernel controls defines the size of the motif/pattern of the convolutional filter. So for this dataset I expect long filters to capture the secondary structure of this rfam family\n",
    "\n",
    "# It is possible to use different strides and dilations, but I think they only take away from the interpretability of the convolutional filters. Also, they can lead to unsampled visible units on the convolution transpose. Likewise using a hidden layer with the kernel size the same as the number of visible units is somewhat equivalent to an RBM if not exactly (I haven't verified). This introduces a positional dependence into the corresponding hidden layer of the model.\n",
    "\n",
    "# So I will use sizes:  11, 25, 46, 86, 100, 112\n",
    "# Motif Finding:  Local Features-------Global Features\n",
    "# Names/Keys for hidden layers in the convolutional topology can be named anything you can use as key in a dictionary\n",
    "# Model outputs are the average of each hidden layer with a set weight\n",
    "thc_default_config[\"convolution_topology\"] = {\"hidden10\": {\"number\": 15, \"kernel\": (9, thc_default_config[\"q\"]), \"stride\": (1, 1), \"padding\": (0, 0), \"dilation\": (1, 1), \"output_padding\": (0, 0), \"weight\": 1.0},\n",
    "                                            \"hidden25\": {\"number\": 15, \"kernel\": (17, thc_default_config[\"q\"]), \"stride\": (1, 1), \"padding\": (0, 0), \"dilation\": (1, 1), \"output_padding\": (0, 0), \"weight\": 1.0},\n",
    "                                            \"hidden46\": {\"number\": 15, \"kernel\": (25, thc_default_config[\"q\"]), \"stride\": (1, 1), \"padding\": (0, 0), \"dilation\": (1, 1), \"output_padding\": (0, 0), \"weight\": 1.0},\n",
    "                                            \"hidden86\": {\"number\": 15, \"kernel\": (33, thc_default_config[\"q\"]), \"stride\": (1, 1), \"padding\": (0, 0), \"dilation\": (1, 1), \"output_padding\": (0, 0), \"weight\": 1.0},\n",
    "                                             }"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### COPY THE ABOVE CELL TO CRBM CONFIGS AS WELL"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Lets create a submission script for a slurm system to run by using the script submit.py\n",
    "\n",
    "# Submission files are stored in rbm_torch/submission/\n",
    "\n",
    "# From Directory rbm_torch I ran\n",
    "\"python submit.py -d cov -r all -p wzhengpu1 -q wildfire -m crbm -e 200 -g 2 --precision double\"\n",
    "\n",
    "# Use python submit.py -h for help!"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "utils",
   "language": "python",
   "display_name": "utils"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}