{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## First let's look at our dataset and determine how it should be split up"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "'/home/jonah/PycharmProjects/phage_display_ML/datasets'"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "## Let's make a directory within datasets to store all our files\n",
    "# Choose a short string 3-5 characters to denote this particular dataset\n",
    "# For this one, I chose \"ribo\" for the ribosomal rna.\n",
    "# Make sure to set \"focus\" in datatype as the same string\n",
    "\n",
    "dataset_focus = \"cov\"\n",
    "dataset_dir = f\"./{dataset_focus}/\"\n",
    "\n",
    "if not os.path.isdir(dataset_dir):\n",
    "    os.mkdir(dataset_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Let's import our data_prep tools\n",
    "import data_prep as dp"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observed Characters: ['C', 'A', 'N', 'G', 'T']\n"
     ]
    }
   ],
   "source": [
    "# The below code can take awhile to run depending on the size of each file\n",
    "cov_df = dp.process_raw_fasta_files(\"r1.txt\", \"r2.txt\", \"r3.txt\", \"r4.txt\", \"r5.txt\", \"r6.txt\", \"r7.txt\", \"r8.txt\", \"r9.txt\", \"r10.txt\", \"r11.txt\", \"r12.txt\", in_dir=\"/mnt/D1/sars-cov-2-data/processed/\", out_dir=dataset_dir, violin_out=\"cov_data_lengths\", input_format=\"fasta\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for round in [f\"r{x}\" for x in range(1, 13)]:\n",
    "    if x > 2:\n",
    "        rseqs = cov_df[cov_df[\"round\"] == round]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "sys.path.append(\"../rbm_torch/\")\n",
    "import utils"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "expected sequence of length 40 at dim 1 (got 41)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-12-4b48e7637dee>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0mr6_df\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcov_df\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mcov_df\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"round\"\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m\"r6\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m \u001B[0mr6_cat\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mutils\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mseq_to_cat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mr6_df\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msequence\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtolist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      4\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0mr6_neighs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mutils\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcount_neighbours\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mr6_cat\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/phage_display_ML/rbm_torch/utils.py\u001B[0m in \u001B[0;36mseq_to_cat\u001B[0;34m(seqs, molecule)\u001B[0m\n\u001B[1;32m    418\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0mseq_to_cat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mseqs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmolecule\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"protein\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    419\u001B[0m     \u001B[0mbase_to_id\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mletter_to_int_dicts\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mmolecule\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 420\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtensor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmap\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;32mlambda\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mbase_to_id\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0my\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0my\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mseqs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlong\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    421\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    422\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: expected sequence of length 40 at dim 1 (got 41)"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "chars_to_remove = []\n",
    "# These all indicate some uncertainty as to the id of the bases. We could also replace these with a gap if we wanted to."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## Looking at the above graph + the length report in our out directory we see this"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 0 Repeat Sequences\r\n",
      "Length: 31 Number of Sequences 1\r\n",
      "Length: 34 Number of Sequences 1\r\n",
      "Length: 35 Number of Sequences 2\r\n",
      "Length: 36 Number of Sequences 12\r\n",
      "Length: 37 Number of Sequences 37\r\n",
      "Length: 38 Number of Sequences 158\r\n",
      "Length: 39 Number of Sequences 831\r\n",
      "Length: 40 Number of Sequences 4363\r\n",
      "Length: 41 Number of Sequences 428468\r\n",
      "Length: 42 Number of Sequences 6728165\r\n",
      "Length: 43 Number of Sequences 525426\r\n"
     ]
    }
   ],
   "source": [
    "!cat \"./thc/r3_len_report.txt\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## We see that the majority of data is length 42. But we can get more data by extending our range from length 41 to length 43. To make the data uniform in length, we will add gaps to the end of all sequences with lengths 41, 42"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "                                       sequence  length round  copy_num\n0   GCGGGGGGGATGGGGAAAACGGCGTTGTAAGAGCATGATGCAC      43   r15  116167.0\n1    GCACGGGAGGGTGGGGGGNAAGCCCTGGGGACAGCAACGTGA      42   r15   99861.0\n2    CGCACAAAAAGGGAGGGGGGGGGGGTAACGAGCGACGGGGCC      42   r15   51713.0\n3    GGGGGGGGGGGGGCCACACAACAGTACTACACGCCGCACAAG      42   r15   44918.0\n4    GCACCAAAGGGCGGGAGGGAGGGGGGAGCCCTGGGGGCCATA      42   r15   37202.0\n0     CATGAGGGAGGGAGGGGGGCAAAAGCTCGGTGGTACCAGCT      41   r16   36802.0\n1    GCGGGAGGGATGGGAGGTCCGAAGCGTTGAGACCACACGGGG      42   r16   34577.0\n5    AAACGCGGCACACAGGGCGGGAGGGTTGGGAAATATTCACGG      42   r15   34410.0\n0   GGAGGGAGGGGGGGAAGAGGTCCCGCGCACCCACTAGACATAA      43   r13   33891.0\n6    GGGCGAACAAGGGAGGGGGGGTGGGGAAGCCCAAGGGCCCGC      42   r15   32895.0\n7    CACAGGGAGGGTGGGTGGGTAGCCTGGAACCGCAGCGGAGAC      42   r15   27732.0\n1    GAGGGTGGGAGGGAGTGGGACCGCGAACACAGCTCCACATGG      42   r13   27148.0\n8    GCGGGGGAGTGGGAAAGGGCCCGAGCACATTAGCGAACGAAG      42   r15   26890.0\n9    GCGGGAGGGTGGGAAAGGGGGCCCAGGGATGCAGCGGACCGA      42   r15   24345.0\n2    CATAGGGAGGGTGGGAGGGCTAGTGGGCCAAAATAACGCGTC      42   r16   23968.0\n10   GGGGGGGGGGGGGAGCTGGGCACGCGACGACATCATAATGGG      42   r15   22576.0\n3    AGGGGAGAAAGGGGGGGGGGGGGGGCAACACGCCTAGAGGGC      42   r16   22068.0\n11   GCGGGTGGGATGGGGAAGACGGGACCCGAACAGTGCGGACAT      42   r15   20957.0\n12  GGAGGGGGGGGGGGGTGGGATTAGCCCGAAGAGCGTGAACAGC      43   r15   19918.0\n13   GAGGATGGGGGGGATACAAGGGCACGACGCGGCTGGGACAGT      42   r15   19499.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sequence</th>\n      <th>length</th>\n      <th>round</th>\n      <th>copy_num</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>GCGGGGGGGATGGGGAAAACGGCGTTGTAAGAGCATGATGCAC</td>\n      <td>43</td>\n      <td>r15</td>\n      <td>116167.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>GCACGGGAGGGTGGGGGGNAAGCCCTGGGGACAGCAACGTGA</td>\n      <td>42</td>\n      <td>r15</td>\n      <td>99861.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>CGCACAAAAAGGGAGGGGGGGGGGGTAACGAGCGACGGGGCC</td>\n      <td>42</td>\n      <td>r15</td>\n      <td>51713.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>GGGGGGGGGGGGGCCACACAACAGTACTACACGCCGCACAAG</td>\n      <td>42</td>\n      <td>r15</td>\n      <td>44918.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>GCACCAAAGGGCGGGAGGGAGGGGGGAGCCCTGGGGGCCATA</td>\n      <td>42</td>\n      <td>r15</td>\n      <td>37202.0</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>CATGAGGGAGGGAGGGGGGCAAAAGCTCGGTGGTACCAGCT</td>\n      <td>41</td>\n      <td>r16</td>\n      <td>36802.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>GCGGGAGGGATGGGAGGTCCGAAGCGTTGAGACCACACGGGG</td>\n      <td>42</td>\n      <td>r16</td>\n      <td>34577.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>AAACGCGGCACACAGGGCGGGAGGGTTGGGAAATATTCACGG</td>\n      <td>42</td>\n      <td>r15</td>\n      <td>34410.0</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>GGAGGGAGGGGGGGAAGAGGTCCCGCGCACCCACTAGACATAA</td>\n      <td>43</td>\n      <td>r13</td>\n      <td>33891.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>GGGCGAACAAGGGAGGGGGGGTGGGGAAGCCCAAGGGCCCGC</td>\n      <td>42</td>\n      <td>r15</td>\n      <td>32895.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>CACAGGGAGGGTGGGTGGGTAGCCTGGAACCGCAGCGGAGAC</td>\n      <td>42</td>\n      <td>r15</td>\n      <td>27732.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>GAGGGTGGGAGGGAGTGGGACCGCGAACACAGCTCCACATGG</td>\n      <td>42</td>\n      <td>r13</td>\n      <td>27148.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>GCGGGGGAGTGGGAAAGGGCCCGAGCACATTAGCGAACGAAG</td>\n      <td>42</td>\n      <td>r15</td>\n      <td>26890.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>GCGGGAGGGTGGGAAAGGGGGCCCAGGGATGCAGCGGACCGA</td>\n      <td>42</td>\n      <td>r15</td>\n      <td>24345.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>CATAGGGAGGGTGGGAGGGCTAGTGGGCCAAAATAACGCGTC</td>\n      <td>42</td>\n      <td>r16</td>\n      <td>23968.0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>GGGGGGGGGGGGGAGCTGGGCACGCGACGACATCATAATGGG</td>\n      <td>42</td>\n      <td>r15</td>\n      <td>22576.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>AGGGGAGAAAGGGGGGGGGGGGGGGCAACACGCCTAGAGGGC</td>\n      <td>42</td>\n      <td>r16</td>\n      <td>22068.0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>GCGGGTGGGATGGGGAAGACGGGACCCGAACAGTGCGGACAT</td>\n      <td>42</td>\n      <td>r15</td>\n      <td>20957.0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>GGAGGGGGGGGGGGGTGGGATTAGCCCGAAGAGCGTGAACAGC</td>\n      <td>43</td>\n      <td>r15</td>\n      <td>19918.0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>GAGGATGGGGGGGATACAAGGGCACGACGCGGCTGGGACAGT</td>\n      <td>42</td>\n      <td>r15</td>\n      <td>19499.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thc_df.sort_values(\"copy_num\", ascending=False).head(20)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "array(['sequence', 'length', 'round', 'copy_num'], dtype=object)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thc_df.columns.values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# So now we can define our datatype\n",
    "\n",
    "# Datatype defines the basics of our data, Each datatype is specified for a group of related fasta files\n",
    "# Focus - > short string specifier that gives the overall dataset we are using\n",
    "# Molecule -> What kind of sequence data? currently protein, dna, and rna are supported\n",
    "# id -> short string specifier ONLY for datasets which have different clustering methods (CLUSTERS ONLY)\n",
    "# process -> How were the gaps added to each dataset, used to name directory (CLUSTERS ONLY)\n",
    "# clusters -> How many clusters are in each data file (1 if no clusters)\n",
    "# cluster_indices -> Define the lengths of data put in each cluster, It is inclusive so [12, 16] includes length 12 and length 16. There must be cluster_indices for each cluster\n",
    "# gap_position_indices -> Index where gaps should be added to each sequence that is short of the maximum length. (-1 means add gaps to the end of the clusters)\n",
    "\n",
    "thc_datatype = {\"focus\": \"thc\", \"molecule\": \"rna\", \"id\": None, \"process\": None, \"clusters\": 1, \"gap_position_indices\": [-1], \"cluster_indices\": [[41, 43]]}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Before we do anything else, we need to copy our datatype to phage_display_ML/rbm_torch/analysis/global_info.py\n",
    "## Also make sure to add the new datatype to the datatype_list in the same file."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Next we need to process the raw files and make our own fasta files with our preferred formatting"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# chars_to_remove = [\"W\", \"D\", \"V\", \"M\", \"B\", \"R\", \"K\", \"Y\", \"H\", \"S\"]\n",
    "# chars_replace = {x: \"-\" for x in chars_to_remove}\n",
    "dp.prepare_data_files(\"thc\", thc_df, target_dir=dataset_dir, character_conversion={\"T\": \"U\", \"N\":\"-\"}, remove_chars=None) # Creates datafiles in target directory"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Now we have generated a data file that we can use for training our RBM or CRBM"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#We will also try scaling the weights based off other information. In this case I am going choose a weight that is representative of both the copy number and the number of sequences that match with less than a threshold of difference b/t one another. To do this I'm going to read in the already processed files with their count number. And write them out with the altered weights in the fasta file"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process Time 1.7240750789642334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# for\n",
    "\n",
    "ffile = \"r6.fasta\"\n",
    "seqs, affs, all_chars, q = utils.fasta_read(dataset_dir + ffile, \"dna\", threads=12, drop_duplicates=False)\n",
    "\n",
    "\n",
    "r6_cat = utils.seq_to_cat(seqs, molecule=\"dna\")\n",
    "r6_neighs = utils.count_neighbours(r6_cat)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(r6_neighs.max(), r6_neighs.min(), r6_neighs.mean(), r6_neighs.median())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# lets double check if only contains characters we know\n",
    "# seqs, chars = dp.fasta_read(dataset_dir+\"rfam.fasta\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C', 'G', '-', 'A', 'U']\n"
     ]
    }
   ],
   "source": [
    "# print(chars)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">seq0-193.0\r\n",
      "AACGACAUUAUACAUCGGGCAUGUCCCUGAGGAUUAGUAACC-\r\n",
      ">seq1-178.0\r\n",
      "AUACUGGCUAUGGGGGUCACUCCAAUAGUCAGAGAGAAUGCA-\r\n",
      ">seq2-165.0\r\n",
      "CACAGGGUAUCGAGAGGAAGCCUGACAACUGAUGGAAUUCA--\r\n",
      ">seq3-83.0\r\n",
      "UGACACGAGAAAAAAUUAGCCCGUGAUCCCACCAUAGUCAAG-\r\n",
      ">seq4-79.0\r\n",
      "CAAGGGAAACCUUACACAUCGAGAGGGGUCCUUCCUAGACC--\r\n",
      ">seq5-55.0\r\n",
      "GUUAUACGGAAUCAAGGAGGAAUAAUCCACGUGCCACACGCG-\r\n",
      ">seq6-53.0\r\n",
      "UAGAAUACGAACGUCGGAUGAUGGGGCAGCGUCUCACAUUAC-\r\n",
      ">seq7-48.0\r\n",
      "GACACAACGUGAUCACUAGACGGAGCCACAAUCCAUUAGAAA-\r\n",
      ">seq8-45.0\r\n",
      "AUCCAGGAUACAUGGCCACACGUCAAAGCGGCUAUAAUACCA-\r\n",
      ">seq9-45.0\r\n",
      "AGCUGCUUCCAACGAAGGCAUGACCCUAAAGAACUGGGAAAC-\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 20 \"./thc/r3.fasta\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Our Last Step is to generate a dataset file, which will inform our models about the location of the data as well as other important details"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "sys.path.append(\"../\")\n",
    "import rbm_torch.analysis.global_info as gi"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "'/home/jonah/PycharmProjects/phage_display_ML/datasets'"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "gi.generate_dataset_file([\"r3.fasta\", \"r5.fasta\", \"r7.fasta\", \"r8.fasta\", \"r9.fasta\", \"r10.fasta\", \"r11.fasta\", \"r12.fasta\", \"r13.fasta\", \"r14.fasta\", \"r15.fasta\", \"r16.fasta\"], gi.supported_datatypes[\"thc\"], destination=\"./dataset_files/\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"data_files\": {\"1\": [\"r3.fasta\", \"r5.fasta\", \"r7.fasta\", \"r8.fasta\", \"r9.fasta\", \"r10.fasta\", \"r11.fasta\", \"r12.fasta\", \"r13.fasta\", \"r14.fasta\", \"r15.fasta\", \"r16.fasta\"]}, \"rounds\": {\"1\": [\"r3\", \"r5\", \"r7\", \"r8\", \"r9\", \"r10\", \"r11\", \"r12\", \"r13\", \"r14\", \"r15\", \"r16\"]}, \"model_names\": {\"weights\": {\"1\": [\"r3_w\", \"r5_w\", \"r7_w\", \"r8_w\", \"r9_w\", \"r10_w\", \"r11_w\", \"r12_w\", \"r13_w\", \"r14_w\", \"r15_w\", \"r16_w\"]}, \"equal\": {\"1\": [\"r3\", \"r5\", \"r7\", \"r8\", \"r9\", \"r10\", \"r11\", \"r12\", \"r13\", \"r14\", \"r15\", \"r16\"]}}, \"local_model_dir\": {\"rbm\": \"/mnt/D1/globus/pig_trained_rbms/None\", \"crbm\": \"/mnt/D1/globus/pig_trained_crbms/None\"}, \"data_dir\": \"../../datasets/thc/\", \"server_model_dir\": {\"rbm\": \"datasets/thc/trained_rbms/\", \"crbm\": \"datasets/thc/trained_crbms/\"}, \"molecule\": \"rna\", \"configkey\": {\"1\": \"thc\"}, \"clusters\": 1}"
     ]
    }
   ],
   "source": [
    "!cat \"./dataset_files/thc.json\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# We're all set to run our models now, except for creating default configs for each dataset\n",
    "# Here is an example one for crbm. It should be appended to crbm_configs.py and added to all_configs\n",
    "\n",
    "thc_default_config = {\"fasta_file\": \"\",\n",
    "          \"v_num\": 43,\n",
    "          \"q\": 5,\n",
    "          \"molecule\": \"rna\",\n",
    "          \"epochs\": 100, # get's overwritten by training script anyway\n",
    "          \"seed\": seed, # this is defined in the config file\n",
    "          \"batch_size\": 10000, # can be raised or lowered depending on memory usage\n",
    "          \"mc_moves\": 4,\n",
    "          \"lr\": 0.006,\n",
    "          \"lr_final\": None, # automatically set as lr * 1e-2\n",
    "          \"decay_after\": 0.75,\n",
    "          \"loss_type\": \"free_energy\",\n",
    "          \"sample_type\": \"gibbs\",\n",
    "          \"sequence_weights\": None,\n",
    "          \"optimizer\": \"AdamW\",\n",
    "          \"weight_decay\": 0.001,  # l2 norm on all parameters\n",
    "          \"l1_2\": 25.0,\n",
    "          \"lf\": 5.0,\n",
    "          \"ld\": 10.0,\n",
    "          \"data_worker_num\": 4\n",
    "          }\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding Whole Convolutions for Input with 43 inputs:\n",
      "Whole Convolution Found: Kernel: 1, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 1, Stride: 2, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 1, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 1, Stride: 2, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 1, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 1, Stride: 2, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 2, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 2, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 2, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 3, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 3, Stride: 2, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 3, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 3, Stride: 2, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 3, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 3, Stride: 2, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 4, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 4, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 4, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 5, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 5, Stride: 2, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 5, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 5, Stride: 2, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 5, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 5, Stride: 2, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 6, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 6, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 6, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 7, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 7, Stride: 2, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 7, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 7, Stride: 2, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 7, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 7, Stride: 2, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 8, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 8, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 8, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 9, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 9, Stride: 2, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 9, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 9, Stride: 2, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 9, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 9, Stride: 2, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 10, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 10, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 10, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 11, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 11, Stride: 2, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 11, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 11, Stride: 2, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 11, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 11, Stride: 2, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 12, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 12, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 12, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 13, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 13, Stride: 2, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 13, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 13, Stride: 2, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 13, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 13, Stride: 2, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 14, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 14, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 14, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 15, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 15, Stride: 2, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 15, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 15, Stride: 2, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 15, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 15, Stride: 2, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 16, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 16, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 16, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 17, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 17, Stride: 2, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 17, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 17, Stride: 2, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 17, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 17, Stride: 2, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 18, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 18, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 18, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 19, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 19, Stride: 2, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 19, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 19, Stride: 2, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 19, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 19, Stride: 2, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 20, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 20, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 20, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 21, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 21, Stride: 2, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 21, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 21, Stride: 2, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 21, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 21, Stride: 2, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 22, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 22, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 22, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 23, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 23, Stride: 2, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 23, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 23, Stride: 2, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 23, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 23, Stride: 2, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 24, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 24, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 24, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 25, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 25, Stride: 2, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 25, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 25, Stride: 2, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 25, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 25, Stride: 2, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 26, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 26, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 26, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 27, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 27, Stride: 2, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 27, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 27, Stride: 2, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 27, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 27, Stride: 2, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 28, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 28, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 28, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 29, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 29, Stride: 2, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 29, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 29, Stride: 2, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 29, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 29, Stride: 2, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 30, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 30, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 30, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 31, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 31, Stride: 2, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 31, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 31, Stride: 2, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 31, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 31, Stride: 2, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 32, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 32, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 32, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 33, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 33, Stride: 2, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 33, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 33, Stride: 2, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 33, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 33, Stride: 2, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 34, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 34, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 34, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 35, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 35, Stride: 2, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 35, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 35, Stride: 2, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 35, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 35, Stride: 2, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 36, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 36, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 36, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 37, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 37, Stride: 2, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 37, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 37, Stride: 2, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 37, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 37, Stride: 2, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 38, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 38, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 38, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 39, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 39, Stride: 2, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 39, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 39, Stride: 2, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 39, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 39, Stride: 2, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 40, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 40, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 40, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 41, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 41, Stride: 2, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 41, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 41, Stride: 2, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 41, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 41, Stride: 2, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 42, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 42, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 42, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 43, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 43, Stride: 2, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 43, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 43, Stride: 2, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 43, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 43, Stride: 2, Dilation: 1, Padding: 2\n"
     ]
    }
   ],
   "source": [
    "# TO figure out the convolution topology we use some helper functions in crbm.py\n",
    "\n",
    "# This function gives all convolutions that fully sample all visible units on the conv transpose for a given data size\n",
    "from rbm_torch.utils import suggest_conv_size\n",
    "\n",
    "# one hot encoded vector of input size (B x V X Q) is the input the CRBM uses\n",
    "visible_num = 43 # V\n",
    "q_states = 5 #Q\n",
    "input_shape = (visible_num, q_states)\n",
    "suggest_conv_size(input_shape, padding_max=2, dilation_max=1, stride_max=2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## My current line of thinking is that having a dilation > 1 or a stride > 1 will introduce some position specific effects."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## Idea: The size of the kernel controls defines the size of the motif/pattern of the convolutional filter. So for this dataset I expect long filters to capture the secondary structure of this rfam family\n",
    "\n",
    "# It is possible to use different strides and dilations, but I think they only take away from the interpretability of the convolutional filters. Also, they can lead to unsampled visible units on the convolution transpose. Likewise using a hidden layer with the kernel size the same as the number of visible units is somewhat equivalent to an RBM if not exactly (I haven't verified). This introduces a positional dependence into the corresponding hidden layer of the model.\n",
    "\n",
    "# So I will use sizes:  11, 25, 46, 86, 100, 112\n",
    "# Motif Finding:  Local Features-------Global Features\n",
    "# Names/Keys for hidden layers in the convolutional topology can be named anything you can use as key in a dictionary\n",
    "# Model outputs are the average of each hidden layer with a set weight\n",
    "thc_default_config[\"convolution_topology\"] = {\"hidden10\": {\"number\": 15, \"kernel\": (9, thc_default_config[\"q\"]), \"stride\": (1, 1), \"padding\": (0, 0), \"dilation\": (1, 1), \"output_padding\": (0, 0), \"weight\": 1.0},\n",
    "                                            \"hidden25\": {\"number\": 15, \"kernel\": (17, thc_default_config[\"q\"]), \"stride\": (1, 1), \"padding\": (0, 0), \"dilation\": (1, 1), \"output_padding\": (0, 0), \"weight\": 1.0},\n",
    "                                            \"hidden46\": {\"number\": 15, \"kernel\": (25, thc_default_config[\"q\"]), \"stride\": (1, 1), \"padding\": (0, 0), \"dilation\": (1, 1), \"output_padding\": (0, 0), \"weight\": 1.0},\n",
    "                                            \"hidden86\": {\"number\": 15, \"kernel\": (33, thc_default_config[\"q\"]), \"stride\": (1, 1), \"padding\": (0, 0), \"dilation\": (1, 1), \"output_padding\": (0, 0), \"weight\": 1.0},\n",
    "                                             }"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### COPY THE ABOVE CELL TO CRBM CONFIGS AS WELL"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Lets create a submission script for a slurm system to run by using the script submit.py\n",
    "\n",
    "# Submission files are stored in rbm_torch/submission/\n",
    "\n",
    "# From Directory rbm_torch I ran\n",
    "\"python submit.py -d ribo -r all -p wzhengpu1 -q wildfire -m crbm -e 200 -g 2 --precision double\"\n",
    "\n",
    "# Use python submit.py -h for help!"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}