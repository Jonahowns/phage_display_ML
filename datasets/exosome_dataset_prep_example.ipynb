{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## First let's look at our dataset and determine how it should be split up"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "'/home/jonah/PycharmProjects/phage_display_ML/datasets'"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "## Let's make a directory within datasets to store all our files\n",
    "# Choose a short string 3-5 characters to denote this particular dataset\n",
    "# For this one, I chose \"ribo\" for the ribosomal rna.\n",
    "# Make sure to set \"focus\" in datatype as the same string\n",
    "\n",
    "dataset_focus = \"exo\"\n",
    "dataset_dir = f\"./{dataset_focus}/\"\n",
    "\n",
    "if not os.path.isdir(dataset_dir):\n",
    "    os.mkdir(dataset_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Let's import our data_prep tools\n",
    "import data_prep as dp"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observed Characters: ['G', 'A', 'C', 'T']\n"
     ]
    }
   ],
   "source": [
    "exo_df = dp.process_raw_fasta_files(*[f\"r{i}.csv\" for i in range(1, 6)], in_dir=\"/mnt/D1/caris_exosome/\", out_dir=dataset_dir, input_format=\"caris\",violin_out=\"exo_data_lengths\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['sequence', 'length', 'round', 'copy_num'], dtype='object')"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exo_df.columns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"./exo/exo_data_lengths.png\" alt=\"EXO Data Lengths\" style=\"height: 50px; width:50px;\"/>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process Time 0.7338004112243652\n",
      "Process Time 0.35588884353637695\n",
      "Process Time 0.17561817169189453\n",
      "Process Time 0.11760854721069336\n",
      "Process Time 5082.692240715027\n"
     ]
    }
   ],
   "source": [
    "import data_prep as dp\n",
    "import rbm_torch.analysis.analysis_methods as am\n",
    "\n",
    "exo_df = am.fetch_data([\"r2\", \"r3\", \"r4\", \"r5\"], dir=\"./exo/\", threads=6, molecule=\"dna\")\n",
    "\n",
    "exo_ct = dp.copynum_topology_faster(exo_df, [\"r2\", \"r3\", \"r4\", \"r5\"])\n",
    "exo_ct.to_csv(\"./exo/exo_ct.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "exo_pd = pd.read_csv(\"./exo/exo_ct.csv\")\n",
    "exo_pd[\"mean\"] = exo_pd.apply(lambda row : np.nanmean(np.asarray([row[x] for x in [\"r2\", \"r3\", \"r4\", \"r5\"]])), axis=1)\n",
    "exo_pd[\"max\"] = exo_pd.apply(lambda row : np.nanmax(np.asarray([row[x] for x in [\"r2\", \"r3\", \"r4\", \"r5\"]])), axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61112 23570 23796\n",
      "16765102.0\n"
     ]
    }
   ],
   "source": [
    "ones = exo_pd[exo_pd[\"mean\"] >= 15.0]\n",
    "max = exo_pd[exo_pd[\"max\"] >= 40.0]\n",
    "ones_max = ones[ones[\"max\"] >= 40.0]\n",
    "print(ones.index.__len__(), ones_max.index.__len__(), max.index.__len__())\n",
    "print(np.sum(exo_pd[\"max\"].values))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# merged r2, r3, r4, r5 sequences, with max count number\n",
    "dp.dataframe_to_fasta(max, \"./exo/m1.fasta\", count_key=\"max\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process Time 0.08887290954589844\n"
     ]
    }
   ],
   "source": [
    "import rbm_torch.utils as utils\n",
    "\n",
    "fasta_file = \"m1.fasta\"\n",
    "\n",
    "seqs, affs, chars, q = utils.fasta_read(dataset_dir+fasta_file, \"protein\")\n",
    "naffs = dp.standardize_affinities(affs, out_plots=dataset_dir+f\"{fasta_file.split('.')[0]}_m\", scale=\"log\", dividers=[15, 50, 80], target_scaling=[1., 1.2, 1.2], divider_type=\"percentile\")\n",
    "naffs = dp.standardize_affinities(affs, out_plots=dataset_dir+f\"{fasta_file.split('.')[0]}_m2\", scale=\"log\", dividers=[15], target_scaling=[1.2], divider_type=\"percentile\")\n",
    "dp.make_weight_file(f\"{dataset_dir}{fasta_file.split('.')[0]}_m\", naffs, \"m\")\n",
    "dp.make_weight_file(f\"{dataset_dir}{fasta_file.split('.')[0]}_m2\", naffs, \"m2\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "import subprocess as sp\n",
    "\n",
    "# no weights\n",
    "os.chdir(\"../rbm_torch\")\n",
    "sp.check_call(f\"python submit.py -d exo -r m1 -p wzhengpu1 -q wildfire -m crbm -e 200 -g 2\", shell=True)\n",
    "sp.call(f\"python submit.py -d exo -r m1 -p wzhengpu1 -q wildfire -m rbm -e 200 -g 1\", shell=True)\n",
    "# weights\n",
    "for wfile in [\"m1_m.json\", \"m1_m2.json\"]:\n",
    "    sp.call(f\"python submit.py -d exo -r m1 -p wzhengpu1 -q wildfire -m crbm -e 200 -g 2 -w {wfile}\", shell=True)\n",
    "    sp.call(f\"python submit.py -d exo -r m1 -p wzhengpu1 -q wildfire -m rbm -e 200 -g 1 -w {wfile}\", shell=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## Looking at the above graph + the length report in our out directory we see this"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 0 Repeat Sequences\r\n",
      "Length: 25 Number of Sequences 94\r\n",
      "Length: 26 Number of Sequences 151\r\n",
      "Length: 27 Number of Sequences 194\r\n",
      "Length: 28 Number of Sequences 299\r\n",
      "Length: 29 Number of Sequences 447\r\n",
      "Length: 30 Number of Sequences 697\r\n",
      "Length: 31 Number of Sequences 1283\r\n",
      "Length: 32 Number of Sequences 2285\r\n",
      "Length: 33 Number of Sequences 5066\r\n",
      "Length: 34 Number of Sequences 27616\r\n",
      "Length: 35 Number of Sequences 1214996\r\n",
      "Length: 36 Number of Sequences 757742\r\n",
      "Length: 37 Number of Sequences 728110\r\n",
      "Length: 38 Number of Sequences 679551\r\n"
     ]
    }
   ],
   "source": [
    "!cat \"./exo/exosome_len_report.txt\" | head -n 80 | tail -n 20"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## We see that the majority of data is length 35. But we can get 2x the data by extending our range from length 35 to length 38. To make the data uniform in length, we will add gaps to the end of all sequences b/t 35 and 37"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# So now we can define our datatype\n",
    "\n",
    "# Datatype defines the basics of our data, Each datatype is specified for a group of related fasta files\n",
    "# Focus - > short string specifier that gives the overall dataset we are using\n",
    "# Molecule -> What kind of sequence data? currently protein, dna, and rna are supported\n",
    "# id -> short string specifier ONLY for datasets which have different clustering methods (CLUSTERS ONLY)\n",
    "# process -> How were the gaps added to each dataset, used to name directory (CLUSTERS ONLY)\n",
    "# clusters -> How many clusters are in each data file (1 if no clusters)\n",
    "# cluster_indices -> Define the lengths of data put in each cluster, It is inclusive so [12, 16] includes length 12 and length 16. There must be cluster_indices for each cluster\n",
    "# gap_position_indices -> Index where gaps should be added to each sequence that is short of the maximum length. (-1 means add gaps to the end of the clusters)\n",
    "\n",
    "exo_datatype = {\"focus\": \"exo\", \"molecule\": \"dna\", \"id\": None, \"process\": None, \"clusters\": 1, \"gap_position_indices\": [-1], \"cluster_indices\": [[35, 38]]}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Before we do anything else, we need to copy our datatype to phage_display_ML/rbm_torch/analysis/global_info.py\n",
    "## Also make sure to add the new datatype to the datatype_list in the same file."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Next we need to process the raw files and make our own fasta files with our preferred formatting"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "chars_to_remove = [\"W\", \"D\", \"V\", \"M\", \"B\", \"R\", \"K\", \"Y\", \"H\", \"S\"]\n",
    "chars_replace = {x: \"-\" for x in chars_to_remove}\n",
    "dp.prepare_data_files(\"exo\", exo_df, target_dir=dataset_dir, remove_chars=None, character_conversion=None) # Creates datafiles in target directory"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Now we have generated a data file that we can use for training our RBM or CRBM"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">seq0-555276\r\n",
      "GCTTGTCAACTCTACAGTGCAAAGCTAATTTTGCT---\r\n",
      ">seq1-434762\r\n",
      "TGTATATCCAGCGGGAGTGCGTCCAGCGTGCCGGG---\r\n",
      ">seq2-175409\r\n",
      "GGTGTGACTTAAAATTTGGTTTCGTTATTCCGCCATGA\r\n",
      ">seq3-167700\r\n",
      "GTTGCCCACTATCGTTCATAACTCTCAATGTCTGTGA-\r\n",
      ">seq4-120928\r\n",
      "GTGTAGCTCGGATGCTGTAGAACATTTTTTTTGCGA--\r\n",
      ">seq5-81378\r\n",
      "ATTGATAATGTATGTTAACCCGTTTCGTTCTCCGTA--\r\n",
      ">seq6-34574\r\n",
      "CTAACTCTATTGACTGCCCACAACCTTACGGTCCTA--\r\n",
      ">seq7-8859\r\n",
      "TTGGCGAGATCATGGAGGGCGCTCACCCATCACATTGA\r\n",
      ">seq8-4086\r\n",
      "GCCAGGAGCACACCACGTTGCAATGGGAATTGAGT---\r\n",
      ">seq9-3543\r\n",
      "TCAAGCCTACTTGAAACCTGTATAAAACCAACTAT---\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 20 \"./exo/r2.fasta\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Our Last Step is to generate a dataset file, which will inform our models about the location of the data as well as other important details"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import rbm_torch.global_info as gi"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "'/home/jonah/PycharmProjects/phage_display_ML/datasets'"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "data_files = [f\"r{i}.fasta\" for i in range(1, 6)]\n",
    "data_files.append(\"r5c.fasta\")\n",
    "gi.generate_dataset_file(data_files, gi.supported_datatypes[\"exo\"], destination=\"./dataset_files/\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat: ./dataset_files/exo.json: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!cat \"./dataset_files/exo.json\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# We're all set to run our models now, except for creating default configs for each dataset\n",
    "# Here is an example one for crbm. It should be appended to crbm_configs.py and added to all_configs\n",
    "\n",
    "exo_default_config = {\"fasta_file\": \"\", # get's overwritten by training script anyway\n",
    "          \"v_num\": 38,\n",
    "          \"q\": 5,\n",
    "          \"molecule\": \"dna\",\n",
    "          \"epochs\": 100, # get's overwritten by training script anyway\n",
    "          \"seed\": seed, # this is defined in the config file\n",
    "          \"batch_size\": 10000, # can be raised or lowered depending on memory usage\n",
    "          \"mc_moves\": 4,\n",
    "          \"lr\": 0.006,\n",
    "          \"lr_final\": None, # automatically set as lr * 1e-2\n",
    "          \"decay_after\": 0.75,\n",
    "          \"loss_type\": \"free_energy\",\n",
    "          \"sample_type\": \"gibbs\",\n",
    "          \"sequence_weights\": None,\n",
    "          \"optimizer\": \"AdamW\",\n",
    "          \"weight_decay\": 0.001,  # l2 norm on all parameters\n",
    "          \"l1_2\": 25.0,\n",
    "          \"lf\": 5.0,\n",
    "          \"ld\": 10.0,\n",
    "          \"data_worker_num\": 4\n",
    "          }\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding Whole Convolutions for Input with 38 inputs:\n",
      "Whole Convolution Found: Kernel: 1, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 1, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 1, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 2, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 2, Stride: 2, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 2, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 2, Stride: 2, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 2, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 2, Stride: 2, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 3, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 3, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 3, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 4, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 4, Stride: 2, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 4, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 4, Stride: 2, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 4, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 4, Stride: 2, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 5, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 5, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 5, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 6, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 6, Stride: 2, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 6, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 6, Stride: 2, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 6, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 6, Stride: 2, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 7, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 7, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 7, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 8, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 8, Stride: 2, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 8, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 8, Stride: 2, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 8, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 8, Stride: 2, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 9, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 9, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 9, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 10, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 10, Stride: 2, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 10, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 10, Stride: 2, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 10, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 10, Stride: 2, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 11, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 11, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 11, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 12, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 12, Stride: 2, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 12, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 12, Stride: 2, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 12, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 12, Stride: 2, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 13, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 13, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 13, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 14, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 14, Stride: 2, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 14, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 14, Stride: 2, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 14, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 14, Stride: 2, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 15, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 15, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 15, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 16, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 16, Stride: 2, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 16, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 16, Stride: 2, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 16, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 16, Stride: 2, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 17, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 17, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 17, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 18, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 18, Stride: 2, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 18, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 18, Stride: 2, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 18, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 18, Stride: 2, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 19, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 19, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 19, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 20, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 20, Stride: 2, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 20, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 20, Stride: 2, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 20, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 20, Stride: 2, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 21, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 21, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 21, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 22, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 22, Stride: 2, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 22, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 22, Stride: 2, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 22, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 22, Stride: 2, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 23, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 23, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 23, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 24, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 24, Stride: 2, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 24, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 24, Stride: 2, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 24, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 24, Stride: 2, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 25, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 25, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 25, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 26, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 26, Stride: 2, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 26, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 26, Stride: 2, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 26, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 26, Stride: 2, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 27, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 27, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 27, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 28, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 28, Stride: 2, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 28, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 28, Stride: 2, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 28, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 28, Stride: 2, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 29, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 29, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 29, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 30, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 30, Stride: 2, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 30, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 30, Stride: 2, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 30, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 30, Stride: 2, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 31, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 31, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 31, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 32, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 32, Stride: 2, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 32, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 32, Stride: 2, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 32, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 32, Stride: 2, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 33, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 33, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 33, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 34, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 34, Stride: 2, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 34, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 34, Stride: 2, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 34, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 34, Stride: 2, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 35, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 35, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 35, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 36, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 36, Stride: 2, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 36, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 36, Stride: 2, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 36, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 36, Stride: 2, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 37, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 37, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 37, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 38, Stride: 1, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 38, Stride: 2, Dilation: 1, Padding: 0\n",
      "Whole Convolution Found: Kernel: 38, Stride: 1, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 38, Stride: 2, Dilation: 1, Padding: 1\n",
      "Whole Convolution Found: Kernel: 38, Stride: 1, Dilation: 1, Padding: 2\n",
      "Whole Convolution Found: Kernel: 38, Stride: 2, Dilation: 1, Padding: 2\n"
     ]
    }
   ],
   "source": [
    "# TO figure out the convolution topology we use some helper functions in crbm.py\n",
    "\n",
    "# This function gives all convolutions that fully sample all visible units on the conv transpose for a given data size\n",
    "from rbm_torch.utils import suggest_conv_size\n",
    "\n",
    "# one hot encoded vector of input size (B x V X Q) is the input the CRBM uses\n",
    "visible_num = 38 # V\n",
    "q_states = 5 #Q\n",
    "input_shape = (visible_num, q_states)\n",
    "suggest_conv_size(input_shape, padding_max=2, dilation_max=1, stride_max=2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## My current line of thinking is that having a dilation > 1 or a stride > 1 will introduce some position specific effects."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## Idea: The size of the kernel controls defines the size of the motif/pattern of the convolutional filter. So for this dataset I expect long filters to capture the secondary structure of this rfam family\n",
    "\n",
    "# It is possible to use different strides and dilations, but I think they only take away from the interpretability of the convolutional filters. Also, they can lead to unsampled visible units on the convolution transpose. Likewise using a hidden layer with the kernel size the same as the number of visible units is somewhat equivalent to an RBM if not exactly (I haven't verified). This introduces a positional dependence into the corresponding hidden layer of the model.\n",
    "\n",
    "# So I will use sizes:  11, 25, 46, 86, 100, 112\n",
    "# Motif Finding:  Local Features-------Global Features\n",
    "# Names/Keys for hidden layers in the convolutional topology can be named anything you can use as key in a dictionary\n",
    "# Model outputs are the average of each hidden layer with a set weight\n",
    "exo_default_config[\"convolution_topology\"] = {\"hidden7\": {\"number\": 10, \"kernel\": (7, exo_default_config[\"q\"]), \"stride\": (1, 1), \"padding\": (0, 0), \"dilation\": (1, 1), \"output_padding\": (0, 0), \"weight\": 1.0},\n",
    "                                            \"hidden13\": {\"number\": 10, \"kernel\": (13, exo_default_config[\"q\"]), \"stride\": (1, 1), \"padding\": (0, 0), \"dilation\": (1, 1), \"output_padding\": (0, 0), \"weight\": 1.0},\n",
    "                                            \"hidden19\": {\"number\": 15, \"kernel\": (19, exo_default_config[\"q\"]), \"stride\": (1, 1), \"padding\": (0, 0), \"dilation\": (1, 1), \"output_padding\": (0, 0), \"weight\": 1.0},\n",
    "                                            \"hidden25\": {\"number\": 15, \"kernel\": (25, exo_default_config[\"q\"]), \"stride\": (1, 1), \"padding\": (0, 0), \"dilation\": (1, 1), \"output_padding\": (0, 0), \"weight\": 1.0},\n",
    "                                              \"hidden31\": {\"number\": 15, \"kernel\": (31, exo_default_config[\"q\"]), \"stride\": (1, 1), \"padding\": (0, 0), \"dilation\": (1, 1), \"output_padding\": (0, 0), \"weight\": 1.0}\n",
    "                                             }"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### COPY THE ABOVE CELL TO CRBM CONFIGS AS WELL!!"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Lets create a submission script for a slurm system to run using the script submit.py\n",
    "\n",
    "# From Directory rbm_torch I ran\n",
    "\"python submit.py -d ribo -r all -p wzhengpu1 -q wildfire -m crbm -e 200 -g 2 --precision double\"\n",
    "\n",
    "# Use python submit.py -h for help!"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import rbm_torch.utils as utils\n",
    "import data_prep as dp\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process Time 2.909881114959717\n",
      "Process Time 0.3979940414428711\n",
      "Process Time 0.25513148307800293\n",
      "Process Time 0.1415846347808838\n",
      "Process Time 0.09172296524047852\n"
     ]
    }
   ],
   "source": [
    "## Now we will make a weight file, one standardized and one with negative weights\n",
    "all_fasta_files = [f\"r{i}.fasta\" for i in range(1, 6)]\n",
    "all_affinities =[]\n",
    "min_vals = []\n",
    "for fasta_file in all_fasta_files:\n",
    "    seqs, affs, chars, q = utils.fasta_read(f\"./exo/{fasta_file}\", \"dna\", threads=12)\n",
    "    # stand_affs = dp.standardize_affinities(affs, out_plot=f\"./exo/{fasta_file.split('.')[0]}_stand_affs\")\n",
    "\n",
    "    stand_affs = dp.standardize_affinities(affs, out_plots=dataset_dir+f\"{fasta_file.split('.')[0]}_sp\", scale=\"linear\", dividers=[15, 50, 80], target_scaling=[2., 20., 5.], divider_type=\"percentile\", negate_index=1, splitter=[0.02, 0.5])\n",
    "\n",
    "    # min_vals.append(min(stand_affs))\n",
    "    # all_affinities.append(stand_affs)\n",
    "    # dp.make_weight_file(f\"./exo/{fasta_file.split('.')[0]}_st_weights\", stand_affs, \"st\")\n",
    "\n",
    "    # stand2_affs = [x if x > 4 else x/1000 for x in stand_affs]\n",
    "    # dp.quick_hist(stand2_affs, f\"./exo/{fasta_file.split('.')[0]})st2_affs.png\", bins=100)\n",
    "\n",
    "    # dp.make_weight_file(f\"./exo/{fasta_file.split('.')[0]}_sd_weights\", stand_affs, \"sd\")\n",
    "    dp.make_weight_file(f\"./exo/{fasta_file.split('.')[0]}_sp_weights\", stand_affs, \"sp\")\n",
    "\n",
    "    # dataset = zip(seqs, stand_affs)\n",
    "    # stand_affs = [(x, a)  for x, a in dataset if min_vals[-1] < a]\n",
    "    # nseqs, naffs = zip(*stand_affs)\n",
    "    # dp.write_fasta(nseqs, naffs, \"./exo/exosome_enriched.fasta\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process Time 0.005297183990478516\n"
     ]
    }
   ],
   "source": [
    "import rbm_torch.utils as utils\n",
    "import data_prep as dp\n",
    "\n",
    "fasta_file = \"r5c.fasta\"\n",
    "\n",
    "seqs, affs, chars, q = utils.fasta_read(f\"./exo/{fasta_file}\", \"dna\", threads=12)\n",
    "stand_affs = dp.standardize_affinities(affs, out_plots=dataset_dir+f\"{fasta_file.split('.')[0]}_lo\", scale=\"linear\", dividers=[10, 40, 80], target_scaling=[1., 2., 2.], divider_type=\"percentile\")\n",
    "\n",
    "dp.make_weight_file(f\"./exo/{fasta_file.split('.')[0]}_lo_weights\", stand_affs, \"lo\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "thresholds = min_vals\n",
    "for fid, fasta_file in enumerate(all_fasta_files):\n",
    "    new_weights = dp.negate_affinites(all_affinities[fid], thresholds[fid], out_plot=f\"./exo/{fasta_file.split('.')[0]}_nw_affs\", negative_factor=100.)\n",
    "    dp.make_weight_file(f\"./exo/{fasta_file.split('.')[0]}_nw_weights\", new_weights, \"nw\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess as sp\n",
    "os.chdir(\"../rbm_torch/\")\n",
    "sp.check_call(f\"python submit.py -d exo -r r5c -p wzhengpu1 -q wildfire -g 1 -e 200 -c 6 --precision single -m crbm -w r5c_lo_weights.json\", shell=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "'/home/jonah/PycharmProjects/phage_display_ML/datasets'"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "#### Now we just need to generate the submission script\n",
    "# run from phage_display/rbm_torch/\n",
    "import subprocess as sp\n",
    "import os\n",
    "\n",
    "\n",
    "# weight_files = [f\"r{i}_st_weights.json\" for i in range(1, 6)]\n",
    "weight_files = [f\"r{i}_sp_weights.json\" for i in range(1, 6)]\n",
    "rounds = [f\"r{i}\" for i in range(1,6)]\n",
    "\n",
    "os.chdir(\"../rbm_torch/\")\n",
    "for i in range(5):\n",
    "    # crbm models\n",
    "    sp.check_call(f\"python submit.py -d exo -r {rounds[i]} -p wzhengpu1 -q wildfire -g 2 -e 200 -c 6 --precision single -m crbm -w {weight_files[i]}\", shell=True)\n",
    "    # rbm models\n",
    "    sp.check_call(f\"python submit.py -d exo -r {rounds[i]} -p wzhengpu1 -q wildfire -g 1 -e 200 -c 6 --precision single -m rbm -w {weight_files[i]}\", shell=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Creating Submission Scripts for HPC Slurm Jobs using submit.py script"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# run from phage_display_ML/rbm_torch/\n",
    "!python submit.py -d exo -r exosome -w exosome_nw_weights.json -p wzhengpu1 -q wildfire -g 2 -e 200 -c 8 --precision single -m crbm\n",
    "!python submit.py -d exo -r exosome -w exosome_st_weights.json -p wzhengpu1 -q wildfire -g 2 -e 200 -c 8 --precision single -m crbm"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "print(\"hi\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import data_prep as dp\n",
    "m1_close_neighs = dp.load_neighbor_file(\"./exo/m1.fasta_10_neighbor_counts.pkl\")\n",
    "m1_far_neighs = dp.load_neighbor_file(\"./exo/m1.fasta_20_neighbor_counts.pkl\")\n",
    "\n",
    "neigh_avg = np.asarray(m1_close_neighs)+np.asarray(m1_far_neighs)/2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dp.quick_hist(neigh_avg)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "dp.make_weight_file(\"m1_ne\", (1/neigh_avg).tolist(), \"ne\", dir=\"./exo/\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess as sp\n",
    "import os\n",
    "os.chdir(\"../rbm_torch/\")\n",
    "sp.call(f\"python submit.py -d exo -r m1 -p wzhengpu1 -q wildfire -m crbm -e 200 -g 2 -w m1_ne.json --precision single\", shell=True) # weights"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}