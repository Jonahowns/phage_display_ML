{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonah/anaconda3/envs/aptamer/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from rbm_torch.utils import data_prep as dp\n",
    "from rbm_torch.utils.utils import fasta_read\n",
    "import rbm_torch.analysis.analysis_methods as am\n",
    "from rbm_torch.utils.seq_utils import prune_similar_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "exo_df = am.fetch_data([\"r2\", \"r3\", \"r4\", \"r5\"], dir=\"./exo/\", threads=6, molecule=\"dna\")\n",
    "exo_ct = dp.copynum_topology_faster(exo_df, [\"r2\", \"r3\", \"r4\", \"r5\"])\n",
    "exo_ct.to_csv(\"./exo/exo_ct.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process Time 0.5486695766448975\n",
      "Process Time 0.3328406810760498\n",
      "Process Time 0.18143343925476074\n",
      "Process Time 0.10362720489501953\n"
     ]
    }
   ],
   "source": [
    "exo_df = am.fetch_data([\"r2\", \"r3\", \"r4\", \"r5\"], dir=\"./exo/raw_rounds/\", threads=6, molecule=\"dna\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "rpm_dict = {}  # normalize counts to reads per million (added option in fasta_read to do this automatically)\n",
    "for r in [\"r2\", \"r3\", \"r4\", \"r5\"]:\n",
    "    round_data = exo_df[exo_df[\"round\"] == r]\n",
    "    rpm_dict[r] = round_data[\"copy_num\"].sum()/1000000"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rpm_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [1]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mrpm_dict\u001B[49m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'rpm_dict' is not defined"
     ]
    }
   ],
   "source": [
    "rpm_dict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "exo_pd = pd.read_csv(\"./exo/exo_ct.csv\")\n",
    "\n",
    "# normalize counts\n",
    "for r in [\"r2\", \"r3\", \"r4\", \"r5\"]:\n",
    "    exo_pd[r] = exo_pd[r].div(rpm_dict[r])\n",
    "\n",
    "# exo_pd[\"mean\"] = exo_pd.apply(lambda row : np.nanmean(np.asarray([row[x] for x in [\"r2\", \"r3\", \"r4\", \"r5\"]])), axis=1)\n",
    "# exo_pd[\"max\"] = exo_pd.apply(lambda row : np.nanmax(np.asarray([row[x] for x in [\"r2\", \"r3\", \"r4\", \"r5\"]])), axis=1)\n",
    "\n",
    "\n",
    "# def fold(dataframe, cols):\n",
    "#     \"\"\" create fold column as col2/col1 for all columns\"\"\"\n",
    "#     for cid, col in enumerate(cols):\n",
    "#         for did, dol in enumerate(cols):\n",
    "#             if cid >= did:\n",
    "#                 continue\n",
    "#             else:\n",
    "#                 dataframe[f\"{dol}/{col}_fold\"] = dataframe.apply(lambda row: row[dol]/row[col] if row[col] != np.nan and row[dol] != np.nan else np.nan, axis=1)\n",
    "#\n",
    "#     return dataframe\n",
    "\n",
    "# exo_pd = fold(exo_pd, [\"r2\", \"r3\", \"r4\", \"r5\"])\n",
    "\n",
    "def enrichment_averge(df, round_names, min_diff=1, max_diff=None, diff_weights=None, round_weights=None):\n",
    "    round_number = len(round_names)\n",
    "\n",
    "    if max_diff is None:\n",
    "        max_diff = round_number-1\n",
    "\n",
    "    if diff_weights is None:\n",
    "        diff_weights = [1. for x in range(min_diff, max_diff+1)]\n",
    "\n",
    "    if round_weights is None:\n",
    "        round_weights = [1. for x in range(len(round_names))]\n",
    "\n",
    "    # first let's remove all the nan values in the dataframe, set nan values as the minimum normalized count for each round\n",
    "    for r in round_names:\n",
    "        df[r] = df[r].fillna(df[r].min())\n",
    "\n",
    "    # Get fold value for round differences\n",
    "    fold_keys = {diff: [] for diff in range(min_diff, max_diff+1)}\n",
    "    for i in range(round_number):\n",
    "        for j in range(round_number):\n",
    "            if i >= j or j - i < min_diff or j - i > max_diff:\n",
    "                continue\n",
    "            fold_column_name = f\"fold_{round_names[j]}v{round_names[i]}\"\n",
    "            fold_keys[j-i].append(fold_column_name)\n",
    "            # fold_diffs.append(j-i)\n",
    "            df[fold_column_name] = df[round_names[j]]/df[round_names[i]] * (round_weights[j] + round_weights[i])\n",
    "\n",
    "    diff_keys = []\n",
    "    for i in range(min_diff, max_diff+1):\n",
    "        diff_avg_key = f\"fold_diff{i}_avg\"\n",
    "        df[diff_avg_key] = df[fold_keys[i]].sum(axis=1).div(len(fold_keys[i])).mul(diff_weights[i-1])\n",
    "        diff_keys.append(diff_avg_key)\n",
    "\n",
    "    df[\"Final_Fold_Avg\"] = df[diff_keys].sum(axis=1).div(len(diff_keys))\n",
    "\n",
    "    return df\n",
    "\n",
    "exo_pd = enrichment_averge(exo_pd, [\"r2\", \"r3\", \"r4\", \"r5\"], min_diff=1, max_diff=None, diff_weights=[0.95, 1.0, 1.0], round_weights=[0.11, 0.12,  0.13, 0.14])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "from copy import copy\n",
    "df_all = exo_df.merge(exo_pd, on=\"sequence\", how='left', indicator=True)\n",
    "single_round_seqs = copy(df_all[df_all['_merge'] == 'left_only'])\n",
    "single_round_seqs.index.__len__()\n",
    "background_seqs = copy(single_round_seqs[single_round_seqs['copy_num'] > 5])\n",
    "background_seqs[\"Fitness_Value\"] = list(np.full((background_seqs.index.__len__()), 0.001))\n",
    "dp.dataframe_to_fasta(background_seqs, \"./exo/background.fasta\", count_key=\"Fitness_Value\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "exo_pd[\"Fitness_Value\"] = dp.scale_values_np(dp.log_scale(exo_pd[\"Final_Fold_Avg\"].tolist(), base=1.0), min=0.01, max=1.0)\n",
    "\n",
    "exo_pd.sort_values(\"Fitness_Value\", ascending=False, inplace=True)\n",
    "dp.dataframe_to_fasta(exo_pd, \"./exo/fold_avg_all3.fasta\", count_key=\"Fitness_Value\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "enriched_exo.sort_values(\"Final_Fold_Avg\", ascending=False, inplace=True)\n",
    "exo_enriched_pruned = prune_similar_sequences(enriched_exo, hamming_threshold=2, molecule=\"dna\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "exo_enriched_pruned = copy(exo_enriched_pruned)\n",
    "exo_enriched_pruned[\"Fitness_Value\"] = dp.scale_values_np(dp.log_scale(exo_enriched_pruned[\"Final_Fold_Avg\"].tolist(), base=1.0), min=0.1, max=1.0)\n",
    "dp.dataframe_to_fasta(exo_enriched_pruned, \"./exo/enriched_trimmed.fasta\", count_key=\"Fitness_Value\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "exo_pd[exo_pd[\"Final_Fold_Avg\"] > 1].index.__len__()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from copy import copy\n",
    "enriched_exo = copy(exo_pd[exo_pd[\"Final_Fold_Avg\"] > 1])\n",
    "\n",
    "enriched_exo[\"Fitness_Value\"] = dp.scale_values_np(dp.log_scale(enriched_exo[\"fold_r5vr2\"].tolist(), base=1.0), min=0.1, max=1.0)\n",
    "\n",
    "enriched_exo.sort_values(\"Fitness_Value\", ascending=False, inplace=True)\n",
    "dp.dataframe_to_fasta(enriched_exo, \"./exo/enriched.fasta\", count_key=\"Fitness_Value\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from copy import copy\n",
    "single_fold_exo = copy(exo_pd)\n",
    "\n",
    "single_fold_exo[\"Fitness_Value\"] = dp.scale_values_np(dp.log_scale(single_fold_exo[\"fold_r5vr2\"].tolist(), base=1.0), min=0.01, max=1.0)\n",
    "\n",
    "single_fold_exo.sort_values(\"Fitness_Value\", ascending=False, inplace=True)\n",
    "dp.dataframe_to_fasta(single_fold_exo, \"./exo/fold_r5vr2.fasta\", count_key=\"Fitness_Value\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "exo_pd.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kept 9956 of 12339\n"
     ]
    }
   ],
   "source": [
    "enriched_exo.sort_values(\"Final_Fold_Avg\", ascending=False, inplace=True)\n",
    "exo_enriched_pruned = prune_similar_sequences(enriched_exo, hamming_threshold=2, molecule=\"dna\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "exo_enriched_pruned = copy(exo_enriched_pruned)\n",
    "exo_enriched_pruned[\"Fitness_Value\"] = dp.scale_values_np(dp.log_scale(exo_enriched_pruned[\"Final_Fold_Avg\"].tolist(), base=1.0), min=0.1, max=1.0)\n",
    "dp.dataframe_to_fasta(exo_enriched_pruned, \"./exo/enriched_trimmed.fasta\", count_key=\"Fitness_Value\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "12339"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exo_pd[exo_pd[\"Final_Fold_Avg\"] > 1].index.__len__()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "from copy import copy\n",
    "enriched_exo = copy(exo_pd[exo_pd[\"Final_Fold_Avg\"] > 1])\n",
    "\n",
    "enriched_exo[\"Fitness_Value\"] = dp.scale_values_np(dp.log_scale(enriched_exo[\"fold_r5vr2\"].tolist(), base=1.0), min=0.1, max=1.0)\n",
    "\n",
    "enriched_exo.sort_values(\"Fitness_Value\", ascending=False, inplace=True)\n",
    "dp.dataframe_to_fasta(enriched_exo, \"./exo/enriched.fasta\", count_key=\"Fitness_Value\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "from copy import copy\n",
    "single_fold_exo = copy(exo_pd)\n",
    "\n",
    "single_fold_exo[\"Fitness_Value\"] = dp.scale_values_np(dp.log_scale(single_fold_exo[\"fold_r5vr2\"].tolist(), base=1.0), min=0.01, max=1.0)\n",
    "\n",
    "single_fold_exo.sort_values(\"Fitness_Value\", ascending=False, inplace=True)\n",
    "dp.dataframe_to_fasta(single_fold_exo, \"./exo/fold_r5vr2.fasta\", count_key=\"Fitness_Value\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "                                      sequence        r2        r3  \\\n222388  GGTCCTCAACCTGCGACGGAGTCCCAACATGTCCA---  0.108311  0.095434   \n235661  TGTTACCTACGCATACCATTACGGGCCTTTGACTGTGA  0.108311  0.095434   \n126562  GGAGCTATGCCGTGATGGGCTCTACTGTTGTTTTTA--  1.083110  0.477169   \n144680  ATCCAGCGTAGCACCCGACATCGCAACCCGTAGAAA--  1.083110  0.477169   \n21663   TTCCGACACCCTCAACGCAGGGTTGAACTTACCCCTGA  1.083110  0.477169   \n\n                   r4             r5  fold_r3vr2    fold_r4vr2     fold_r5vr2  \\\n222388       0.196595  315185.882054    0.202655      0.435623  727502.203398   \n235661       0.196595   69177.159597    0.202655      0.435623  159672.557995   \n126562  176580.854909       0.117744    0.101328  39127.527470       0.027177   \n144680  109302.011029   14785.317826    0.101328  24219.598672    3412.700856   \n21663    93698.952876       0.117744    0.101328  20762.207514       0.027177   \n\n          fold_r4vr3     fold_r5vr3    fold_r5vr4  fold_diff1_avg  \\\n222388      0.515004  858693.356321  4.328705e+05   137075.895715   \n235661      0.515004  188466.459754  9.500665e+04    30085.665515   \n126562  92514.886024       0.064156  1.800354e-07    29296.412661   \n144680  57265.908571    8056.232789  3.652299e-02    18134.248033   \n21663   49091.097392       0.064156  3.392867e-07    15545.546261   \n\n        fold_diff2_avg  fold_diff3_avg  Final_Fold_Avg  Fitness_Value  \n222388   429346.895972   727502.203398   431308.331695       1.000000  \n235661    94233.447689   159672.557995    94663.890400       0.883918  \n126562    19563.795813        0.027177    16286.745217       0.749201  \n144680    16137.915731     3412.700856    12561.621540       0.729323  \n21663     10381.135835        0.027177     8642.236425       0.700699  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sequence</th>\n      <th>r2</th>\n      <th>r3</th>\n      <th>r4</th>\n      <th>r5</th>\n      <th>fold_r3vr2</th>\n      <th>fold_r4vr2</th>\n      <th>fold_r5vr2</th>\n      <th>fold_r4vr3</th>\n      <th>fold_r5vr3</th>\n      <th>fold_r5vr4</th>\n      <th>fold_diff1_avg</th>\n      <th>fold_diff2_avg</th>\n      <th>fold_diff3_avg</th>\n      <th>Final_Fold_Avg</th>\n      <th>Fitness_Value</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>222388</th>\n      <td>GGTCCTCAACCTGCGACGGAGTCCCAACATGTCCA---</td>\n      <td>0.108311</td>\n      <td>0.095434</td>\n      <td>0.196595</td>\n      <td>315185.882054</td>\n      <td>0.202655</td>\n      <td>0.435623</td>\n      <td>727502.203398</td>\n      <td>0.515004</td>\n      <td>858693.356321</td>\n      <td>4.328705e+05</td>\n      <td>137075.895715</td>\n      <td>429346.895972</td>\n      <td>727502.203398</td>\n      <td>431308.331695</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>235661</th>\n      <td>TGTTACCTACGCATACCATTACGGGCCTTTGACTGTGA</td>\n      <td>0.108311</td>\n      <td>0.095434</td>\n      <td>0.196595</td>\n      <td>69177.159597</td>\n      <td>0.202655</td>\n      <td>0.435623</td>\n      <td>159672.557995</td>\n      <td>0.515004</td>\n      <td>188466.459754</td>\n      <td>9.500665e+04</td>\n      <td>30085.665515</td>\n      <td>94233.447689</td>\n      <td>159672.557995</td>\n      <td>94663.890400</td>\n      <td>0.883918</td>\n    </tr>\n    <tr>\n      <th>126562</th>\n      <td>GGAGCTATGCCGTGATGGGCTCTACTGTTGTTTTTA--</td>\n      <td>1.083110</td>\n      <td>0.477169</td>\n      <td>176580.854909</td>\n      <td>0.117744</td>\n      <td>0.101328</td>\n      <td>39127.527470</td>\n      <td>0.027177</td>\n      <td>92514.886024</td>\n      <td>0.064156</td>\n      <td>1.800354e-07</td>\n      <td>29296.412661</td>\n      <td>19563.795813</td>\n      <td>0.027177</td>\n      <td>16286.745217</td>\n      <td>0.749201</td>\n    </tr>\n    <tr>\n      <th>144680</th>\n      <td>ATCCAGCGTAGCACCCGACATCGCAACCCGTAGAAA--</td>\n      <td>1.083110</td>\n      <td>0.477169</td>\n      <td>109302.011029</td>\n      <td>14785.317826</td>\n      <td>0.101328</td>\n      <td>24219.598672</td>\n      <td>3412.700856</td>\n      <td>57265.908571</td>\n      <td>8056.232789</td>\n      <td>3.652299e-02</td>\n      <td>18134.248033</td>\n      <td>16137.915731</td>\n      <td>3412.700856</td>\n      <td>12561.621540</td>\n      <td>0.729323</td>\n    </tr>\n    <tr>\n      <th>21663</th>\n      <td>TTCCGACACCCTCAACGCAGGGTTGAACTTACCCCTGA</td>\n      <td>1.083110</td>\n      <td>0.477169</td>\n      <td>93698.952876</td>\n      <td>0.117744</td>\n      <td>0.101328</td>\n      <td>20762.207514</td>\n      <td>0.027177</td>\n      <td>49091.097392</td>\n      <td>0.064156</td>\n      <td>3.392867e-07</td>\n      <td>15545.546261</td>\n      <td>10381.135835</td>\n      <td>0.027177</td>\n      <td>8642.236425</td>\n      <td>0.700699</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exo_pd.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "242496"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exo_pd.index.__len__()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "                                 sequence        r2        r3        r4  \\\n0  TGCGGGGCAATTTGAACACACCCGCAATCCCAGTTTGA  3.465951  2.958446  0.098298   \n1  ATGGATCACAAGGTGTTTCTGTTTTTTTTGGGGTAA--  0.108311  0.095434  0.098298   \n2  TTTGAACGTCCGCAGCTGCAATCGGGCGCTTAGCCA--  2.057908  1.240639  0.098298   \n3  TGACGTAGTGACTGGATCTACACATTTTTCTTACT---  1.191421  0.477169  0.098298   \n4  ATTAAGTTGGTAGCCGCCACCATGTTTGTCAGATC---  0.974799  0.381735  4.718280   \n\n         r5       max  fold_r3vr2  fold_r4vr2  fold_r5vr2  fold_r4vr3  \\\n0  0.117744  3.465951    1.792506    0.060976    0.074737    0.074759   \n1  0.235487  0.235487    1.850329    1.951230    4.783195    2.317517   \n2  0.117744  2.057908    1.266014    0.102696    0.125874    0.178271   \n3  0.117744  1.191421    0.841058    0.177385    0.217418    0.463503   \n4  0.117744  4.718280    0.822368   10.406561    0.265733   27.810210   \n\n   fold_r5vr3  fold_r5vr4  fold_diff1_avg  fold_diff2_avg  fold_diff3_avg  \\\n0    0.091538    2.814902        1.560722        0.091508        0.097159   \n1    5.675364    5.629803        3.265883        4.575956        6.218153   \n2    0.218283    2.814902        1.419729        0.192588        0.163636   \n3    0.567536    2.814902        1.373154        0.446953        0.282643   \n4    0.709420    0.058644        9.563741        6.669589        0.345453   \n\n   Final_Fold_Avg  \n0        0.583130  \n1        4.686664  \n2        0.591984  \n3        0.700917  \n4        5.526261  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sequence</th>\n      <th>r2</th>\n      <th>r3</th>\n      <th>r4</th>\n      <th>r5</th>\n      <th>max</th>\n      <th>fold_r3vr2</th>\n      <th>fold_r4vr2</th>\n      <th>fold_r5vr2</th>\n      <th>fold_r4vr3</th>\n      <th>fold_r5vr3</th>\n      <th>fold_r5vr4</th>\n      <th>fold_diff1_avg</th>\n      <th>fold_diff2_avg</th>\n      <th>fold_diff3_avg</th>\n      <th>Final_Fold_Avg</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>TGCGGGGCAATTTGAACACACCCGCAATCCCAGTTTGA</td>\n      <td>3.465951</td>\n      <td>2.958446</td>\n      <td>0.098298</td>\n      <td>0.117744</td>\n      <td>3.465951</td>\n      <td>1.792506</td>\n      <td>0.060976</td>\n      <td>0.074737</td>\n      <td>0.074759</td>\n      <td>0.091538</td>\n      <td>2.814902</td>\n      <td>1.560722</td>\n      <td>0.091508</td>\n      <td>0.097159</td>\n      <td>0.583130</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ATGGATCACAAGGTGTTTCTGTTTTTTTTGGGGTAA--</td>\n      <td>0.108311</td>\n      <td>0.095434</td>\n      <td>0.098298</td>\n      <td>0.235487</td>\n      <td>0.235487</td>\n      <td>1.850329</td>\n      <td>1.951230</td>\n      <td>4.783195</td>\n      <td>2.317517</td>\n      <td>5.675364</td>\n      <td>5.629803</td>\n      <td>3.265883</td>\n      <td>4.575956</td>\n      <td>6.218153</td>\n      <td>4.686664</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>TTTGAACGTCCGCAGCTGCAATCGGGCGCTTAGCCA--</td>\n      <td>2.057908</td>\n      <td>1.240639</td>\n      <td>0.098298</td>\n      <td>0.117744</td>\n      <td>2.057908</td>\n      <td>1.266014</td>\n      <td>0.102696</td>\n      <td>0.125874</td>\n      <td>0.178271</td>\n      <td>0.218283</td>\n      <td>2.814902</td>\n      <td>1.419729</td>\n      <td>0.192588</td>\n      <td>0.163636</td>\n      <td>0.591984</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>TGACGTAGTGACTGGATCTACACATTTTTCTTACT---</td>\n      <td>1.191421</td>\n      <td>0.477169</td>\n      <td>0.098298</td>\n      <td>0.117744</td>\n      <td>1.191421</td>\n      <td>0.841058</td>\n      <td>0.177385</td>\n      <td>0.217418</td>\n      <td>0.463503</td>\n      <td>0.567536</td>\n      <td>2.814902</td>\n      <td>1.373154</td>\n      <td>0.446953</td>\n      <td>0.282643</td>\n      <td>0.700917</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ATTAAGTTGGTAGCCGCCACCATGTTTGTCAGATC---</td>\n      <td>0.974799</td>\n      <td>0.381735</td>\n      <td>4.718280</td>\n      <td>0.117744</td>\n      <td>4.718280</td>\n      <td>0.822368</td>\n      <td>10.406561</td>\n      <td>0.265733</td>\n      <td>27.810210</td>\n      <td>0.709420</td>\n      <td>0.058644</td>\n      <td>9.563741</td>\n      <td>6.669589</td>\n      <td>0.345453</td>\n      <td>5.526261</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exo_pd.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23382\n"
     ]
    }
   ],
   "source": [
    "from copy import copy\n",
    "enriched = copy(exo_pd[(exo_pd[\"r5/r4_fold\"] > 2) | (exo_pd[\"r5/r3_fold\"] > 3)])\n",
    "enriched[\"fold\"] = enriched.apply(lambda row: np.nanmax(np.asarray([row[\"r5/r4_fold\"], row[\"r5/r3_fold\"]])), axis=1)\n",
    "print(enriched.index.__len__())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kept 20919 of 23382\n"
     ]
    }
   ],
   "source": [
    "enriched.sort_values(\"fold\", ascending=False, inplace=True)\n",
    "enriched_trimmed = prune_similar_sequences(enriched, hamming_threshold=4, molecule=\"dna\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "dp.dataframe_to_fasta(enriched_trimmed, \"./exo/enriched.fasta\", count_key=\"fold\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process Time 0.024022579193115234\n"
     ]
    }
   ],
   "source": [
    "seqs, folds, chars, q = fasta_read(\"./exo/enriched.fasta\", \"dna\", threads=6)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "std_folds = dp.standardize_affinities(folds, out_plots=\"./exo/enriched\", scale=\"log\", dividers=[10], target_scaling=[2.49], divider_type=\"percentile\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "dp.make_weight_file(\"./exo/en_fold_st\", std_folds)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "top50_seqs, top50cns, chars50, q50 = dp.fasta_read(\"./exo/fold_avg_top50.fasta\", \"dna\", threads=12)\n",
    "v_seqs, vcns, vchars, vq = dp.fasta_read(\"./exo/pev_n.fasta\", \"dna\", threads=12)\n",
    "l_seqs, lcns, lchars, lq = dp.fasta_read(\"./exo/pev_n.fasta\", \"dna\", threads=12)\n",
    "\n",
    "avoid_seqs = v_seqs+l_seqs\n",
    "\n",
    "train_set = [(x, top50cns[xid]) for xid, x in enumerate(top50_seqs) if x not in avoid_seqs ]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process Time 0.04651784896850586\n",
      "Process Time 0.0036745071411132812\n",
      "Process Time 0.0025069713592529297\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "49670"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_set)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "train_seqs, train_cns = list(zip(*train_set))\n",
    "dp.write_fasta(train_seqs, train_cns, \"./exo/caris_train.fasta\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "(1.0,\n 0.9000297513733405,\n 0.7780754141359186,\n 0.7622574079643377,\n 0.7363015694770522,\n 0.7130464028274566,\n 0.7105146831676591,\n 0.6624593833236179,\n 0.6472345141934827,\n 0.639186000091549,\n 0.6326339240624735,\n 0.6307539543605172,\n 0.6304063060372952,\n 0.6265485045868101,\n 0.6208354108769182,\n 0.6182549974264525,\n 0.6132541628654202,\n 0.5989156506775591,\n 0.5982639641013371,\n 0.5872403294697864,\n 0.5844197974566168,\n 0.5838517819461584,\n 0.5835775379629128,\n 0.5834703675404612,\n 0.5797468849696881,\n 0.5751526829114473,\n 0.5721593456225001,\n 0.5629739447772547,\n 0.558867946962121,\n 0.5577473468870832,\n 0.556709957133715,\n 0.5516255359553985,\n 0.5441698557429883,\n 0.5408493533199272,\n 0.5378691846793252,\n 0.5359962262084343,\n 0.5347779929709165,\n 0.5339783345268935,\n 0.5333611604001016,\n 0.5301924004254517,\n 0.5277685574314137,\n 0.5272433424778459,\n 0.5248938835234082,\n 0.5246609335799262,\n 0.5245446620441433,\n 0.5226984386719387,\n 0.518775378904574,\n 0.5175758905695559,\n 0.5169231762270481,\n 0.5166939131888387,\n 0.5165193584785545,\n 0.5151757063777468,\n 0.5145260641311632,\n 0.5141280207176757,\n 0.513946707035143,\n 0.5129780774021843,\n 0.5118156835748688,\n 0.5102204897642493,\n 0.5101789750164544,\n 0.5096787480383385,\n 0.5085337928961265,\n 0.5083259495077024,\n 0.5082404707090121,\n 0.5074228458600639,\n 0.5057079521314591,\n 0.5025362248665824,\n 0.5000545423166841,\n 0.4968250896007115,\n 0.495804611935625,\n 0.49554587444782705,\n 0.49413086817969076,\n 0.4931165965312605,\n 0.491892385847161,\n 0.491812693820566,\n 0.49042646696197334,\n 0.49031429922670755,\n 0.4900521096556838,\n 0.48909914037079294,\n 0.4882040101417805,\n 0.48814147239846994,\n 0.48691645141402545,\n 0.48619765926995795,\n 0.4857838646586617,\n 0.48554292551773415,\n 0.48526600741833786,\n 0.48440516381204296,\n 0.4820102748827354,\n 0.4805945065140643,\n 0.4805945065140643,\n 0.48005419334855987,\n 0.47984880282047504,\n 0.478747496389089,\n 0.47867201640259116,\n 0.4783029209165014,\n 0.47681477418348595,\n 0.47636349354768726,\n 0.4757362701819667,\n 0.4743922033683827,\n 0.4742491153161081,\n 0.4738556807292969,\n 0.47136513184236756,\n 0.471095119765918,\n 0.4707939058014773,\n 0.4704154425199492,\n 0.4701110996658153,\n 0.4691590843696899,\n 0.46894199420585136,\n 0.46770355694429067,\n 0.4671931767477594,\n 0.4669878010164028,\n 0.46679717717660346,\n 0.46679701574520127,\n 0.46618329439824774,\n 0.46520474454545424,\n 0.46498471925082485,\n 0.46487530650689207,\n 0.4637931188672094,\n 0.4633081553561401,\n 0.4628385217867638,\n 0.46260746881692466,\n 0.46235060261464345,\n 0.46181402316075115,\n 0.4617154686434782,\n 0.46166069225214323,\n 0.46148708055941756,\n 0.4609575029211528,\n 0.4609117352645603,\n 0.4605239562875251,\n 0.459725343030312,\n 0.4594569740898291,\n 0.4579152280840887,\n 0.45752996083700687,\n 0.4573623575497417,\n 0.45734375362532276,\n 0.4570376638871811,\n 0.4563365594297432,\n 0.45624250866391713,\n 0.4559595485858563,\n 0.4557702315174408,\n 0.45548956568079024,\n 0.4552524337557897,\n 0.45480777409671785,\n 0.45452073533705206,\n 0.4543849913304291,\n 0.45426104101869974,\n 0.4541687157734391,\n 0.4539440724266555,\n 0.45275959099546415,\n 0.4526038020874533,\n 0.451360199989764,\n 0.4511571816121951,\n 0.4493945305415541,\n 0.44833068601054166,\n 0.4476066269039451,\n 0.44739486321953115,\n 0.4471165492396808,\n 0.4464157280075213,\n 0.44608716852312186,\n 0.44575696327439746,\n 0.4455551893391106,\n 0.44486824316948226,\n 0.4442681475308747,\n 0.44419375105330383,\n 0.44408066169005045,\n 0.443724185956645,\n 0.44362635414754614,\n 0.443220606277071,\n 0.4432143404919115,\n 0.44309707450335295,\n 0.4419820701274827,\n 0.44185648934150773,\n 0.44154231174999026,\n 0.4411991227362603,\n 0.4404388689604583,\n 0.43923701705262075,\n 0.43914671259778043,\n 0.43883249477092023,\n 0.4382872535963333,\n 0.43811527489648483,\n 0.4380243176886489,\n 0.43794922630121835,\n 0.43694997616283077,\n 0.43678845084292234,\n 0.43678731344888466,\n 0.43635414963452995,\n 0.436044415213621,\n 0.4354435879125529,\n 0.4349931272051665,\n 0.43473174891824157,\n 0.4344714037684563,\n 0.4341426300968711,\n 0.43328220657636396,\n 0.43270717383195667,\n 0.4324773206960149,\n 0.4321156680112682,\n 0.4319352180856604,\n 0.431416335248488,\n 0.43128105054140287,\n 0.43125126009763554,\n 0.43081936686683825,\n 0.4302816382774533,\n 0.4290260879882637,\n 0.4288984156387889,\n 0.42815457134952234,\n 0.42743001898741745,\n 0.4270461985828535,\n 0.4269914339797268,\n 0.42675030014018595,\n 0.4264020777104169,\n 0.4263181169206239,\n 0.42610541186802564,\n 0.42532642684577676,\n 0.42497762780811743,\n 0.4249627461534331,\n 0.42477303795203675,\n 0.4247536420125508,\n 0.4247521851047523,\n 0.42448303716485136,\n 0.4241438416132971,\n 0.4241438416132971,\n 0.42399050603676525,\n 0.423836812968365,\n 0.423528347660882,\n 0.42350495401347504,\n 0.42337357204479775,\n 0.42306292635588394,\n 0.4222890280715185,\n 0.4215545977795316,\n 0.4215355605498728,\n 0.4211676686847824,\n 0.4209066587672159,\n 0.42084642641775366,\n 0.42036160862413285,\n 0.41987319885285473,\n 0.41987319885285473,\n 0.4193811434810131,\n 0.41924064736794536,\n 0.4186910933209722,\n 0.41845734997227957,\n 0.4184114645634418,\n 0.41821852659497544,\n 0.4178354209706776,\n 0.4175448506227833,\n 0.41730502396903896,\n 0.4172054132452002,\n 0.4170350368790545,\n 0.416864219032337,\n 0.41669295741116663,\n 0.41669295741116663,\n 0.41669295741116663,\n 0.4164894195892774,\n 0.41634909358013256,\n 0.41634909358013256,\n 0.41548150388040006,\n 0.41548150388040006,\n 0.41530660729298136,\n 0.41490002897199546,\n 0.41477911608946944,\n 0.4146023435351054,\n 0.4144250956839998,\n 0.4144250956839998,\n 0.4142473699733546,\n 0.41406916381958786,\n 0.4137593601548762,\n 0.4137356222215358,\n 0.41297700156925027,\n 0.41274450071293084,\n 0.4125026546537934,\n 0.4117067094306303,\n 0.4110249683120365,\n 0.4105883666017503,\n 0.4105883666017503,\n 0.410399974922262,\n 0.4102110433153425,\n 0.4100215686772483,\n 0.4100215686772483,\n 0.4093593289717083,\n 0.4092581767923142,\n 0.4090747493017224,\n 0.4077368306754927,\n 0.4077043492345909,\n 0.40750752010094043,\n 0.4073101015179377,\n 0.4072606438071808,\n 0.4072295895296374,\n 0.40711208994449666,\n 0.40671427350154166,\n 0.40611301102049385,\n 0.40611301102049385,\n 0.4055062140275818,\n 0.4047597295107618,\n 0.4046085023547596,\n 0.40444436116576205,\n 0.40415562888965767,\n 0.40386023982723507,\n 0.4037419365039929,\n 0.4036996216746707,\n 0.4036604250670695,\n 0.4036515730461687,\n 0.4033136694284484,\n 0.40323224745706643,\n 0.40323224745706643,\n 0.4028931990573072,\n 0.4028931990573072,\n 0.4023372951566902,\n 0.4021721134627976,\n 0.4020767874013576,\n 0.4017432397261951,\n 0.400929486149754,\n 0.400693218471242,\n 0.4006586873051559,\n 0.40051785927351385,\n 0.4004415417747208,\n 0.40021982046021276,\n 0.40021982046021276,\n 0.4001205167475747,\n 0.39999928651851446,\n 0.3995460276308578,\n 0.39944391683093877,\n 0.3993332232295107,\n 0.3993332232295107,\n 0.3988714573034707,\n 0.3984345392706206,\n 0.398288147869332,\n 0.397879279571899,\n 0.39777200602482793,\n 0.39706311603167355,\n 0.39706311603167355,\n 0.39676924275968134,\n 0.39659956068059016,\n 0.3963665548753109,\n 0.3956758147746541,\n 0.3955987166766207,\n 0.3954603847863212,\n 0.3951890097819206,\n 0.39506951462999484,\n 0.3950075329469755,\n 0.39436942025810745,\n 0.39423159075400754,\n 0.39423159075400754,\n 0.39412509072649593,\n 0.39392059322083606,\n 0.3937476158455553,\n 0.39350428940271426,\n 0.39350428940271426,\n 0.3932170009680228,\n 0.3926777249673018,\n 0.3925219014569293,\n 0.3923194838232388,\n 0.39227399983667954,\n 0.39227399983667954,\n 0.39227399983667954,\n 0.39205789735902885,\n 0.39202516245690033,\n 0.3919662358782553,\n 0.39172343646823377,\n 0.39107948019795624,\n 0.39107948019795624,\n 0.3910389431757983,\n 0.391032853222028,\n 0.39084845696996745,\n 0.39025649351476993,\n 0.39025649351476993,\n 0.3899999078187058,\n 0.3899999078187058,\n 0.38985078760577285,\n 0.3897423195222285,\n 0.3895696297376994,\n 0.38903080756224323,\n 0.38896345990412845,\n 0.38870178160922614,\n 0.3884390604396939,\n 0.3880623076833075,\n 0.3879015352942092,\n 0.387644555722056,\n 0.387644555722056,\n 0.387644555722056,\n 0.3873775785833037,\n 0.3873775785833037,\n 0.3873659905309369,\n 0.3872951533413196,\n 0.3869837443876393,\n 0.38684035856500937,\n 0.38673991493949306,\n 0.38657009784613866,\n 0.38629872457771486,\n 0.38629872457771486,\n 0.3862960681186599,\n 0.3861866204060442,\n 0.38609743153516884,\n 0.3860262295620661,\n 0.3860262295620661,\n 0.38597804185419954,\n 0.3857526034869885,\n 0.38547783692383647,\n 0.3854411479120416,\n 0.38520192032557327,\n 0.3849248440247807,\n 0.3849248440247807,\n 0.3846958876597397,\n 0.38442071896650004,\n 0.3840865583843376,\n 0.3840865583843376,\n 0.38395834130975753,\n 0.3838047441195666,\n 0.3838047441195666,\n 0.38353021102329815,\n 0.3835217199367854,\n 0.3835217199367854,\n 0.3835217199367854,\n 0.3835217199367854,\n 0.3835217199367854,\n 0.3832374754020583,\n 0.38275194425981346,\n 0.3826652828609002,\n 0.3826652828609002,\n 0.38249465566375934,\n 0.3820880802707368,\n 0.3820880802707368,\n 0.38200155905444794,\n 0.3817975726392601,\n 0.3817975726392601,\n 0.3817975726392601,\n 0.3817037517718269,\n 0.38150577912123995,\n 0.38150577912123995,\n 0.38150577912123995,\n 0.38150577912123995,\n 0.38150577912123995,\n 0.38148208236080733,\n 0.3812126882824953,\n 0.3812126882824953,\n 0.3811669219683287,\n 0.38114551751593084,\n 0.38084502698759615,\n 0.38032551518567387,\n 0.3801996755255226,\n 0.3800271176167827,\n 0.3800271176167827,\n 0.3799631436131973,\n 0.3799631436131973,\n 0.37988365899217574,\n 0.37972736320247247,\n 0.37972736320247247,\n 0.37936940245104567,\n 0.37887395722362266,\n 0.3788198340723727,\n 0.3785210476884971,\n 0.3783240363676477,\n 0.37820779855642417,\n 0.3780355623731224,\n 0.3775900274767861,\n 0.37754874237190766,\n 0.3772789573090842,\n 0.3769664123164248,\n 0.37689769708876925,\n 0.37686901099283715,\n 0.3766523784474806,\n 0.3763587594081312,\n 0.37633684144915247,\n 0.3761861217529582,\n 0.3760197868626878,\n 0.3757012000197054,\n 0.3755093512719668,\n 0.3753908666451357,\n 0.3753810660381229,\n 0.3753810660381229,\n 0.3753440875482815,\n 0.3752286910583568,\n 0.3749790637066393,\n 0.37486033519126993,\n 0.3744112291471169,\n 0.37438359163843676,\n 0.37414856121754675,\n 0.37399369142967753,\n 0.37390696721559075,\n 0.3737600265699745,\n 0.37375665268495495,\n 0.37375665268495495,\n 0.37348575783896815,\n 0.37344756033760346,\n 0.3732060516675963,\n 0.37300199571901776,\n 0.37299978732606087,\n 0.3729177192477872,\n 0.3726843369482018,\n 0.372427672091827,\n 0.37227122558771536,\n 0.3720911980759148,\n 0.3720911980759148,\n 0.3717529978439924,\n 0.3717529978439924,\n 0.3717529978439924,\n 0.37141305359263693,\n 0.3713383552107087,\n 0.3709003480374684,\n 0.3708699972915962,\n 0.3707278604278996,\n 0.37062263893006503,\n 0.37045950729521016,\n 0.36968652921744216,\n 0.36968652921744216,\n 0.3695361172250815,\n 0.36933573106131945,\n 0.36927368611898054,\n 0.36924138056226696,\n 0.3689830561759328,\n 0.3689830561759328,\n 0.3689830561759328,\n 0.3686667364255977,\n 0.3685967012457149,\n 0.36844891227887105,\n 0.3682719951353577,\n 0.3682332917453945,\n 0.36806977663539486,\n 0.3679135676132249,\n 0.3675963440184693,\n 0.3675531806134984,\n 0.3675531806134984,\n 0.3675531806134984,\n 0.36744473949274153,\n 0.36719081259392683,\n 0.36719081259392683,\n 0.36719081259392683,\n 0.366826441655045,\n 0.36675205656940646,\n 0.36662341652691277,\n 0.36660544294528397,\n 0.36654885876392945,\n 0.3664600455322326,\n 0.3664600455322326,\n 0.36613332582416136,\n 0.3660126932620802,\n 0.3659454730856109,\n 0.36583891297898435,\n 0.3658093127933112,\n 0.3658093127933112,\n 0.36572108680134613,\n 0.36572108680134613,\n 0.3656172507056998,\n 0.36559775759492624,\n 0.36554570651567664,\n 0.3653328344494107,\n 0.3653328344494107,\n 0.3653216931029003,\n 0.36459688128844947,\n 0.36421784499813553,\n 0.3638366167315399,\n 0.3638366167315399,\n 0.363453170988617,\n 0.36344544160893055,\n 0.3630674818217401,\n 0.3630674818217401,\n 0.3630674818217401,\n 0.36305175368076714,\n 0.3628902537438435,\n 0.36267952282516436,\n 0.36267952282516436,\n 0.36228926712417897,\n 0.36228926712417897,\n 0.3622555771299404,\n 0.3622555771299404,\n 0.3621115805811617,\n 0.3621115805811617,\n 0.36189668736393565,\n 0.36189668736393565,\n 0.361851141240699,\n 0.3616074970857808,\n 0.3615351510777475,\n 0.3615351510777475,\n 0.3615017556979429,\n 0.3615017556979429,\n 0.3615017556979429,\n 0.36110444377621326,\n 0.3610995276765297,\n 0.36074036979251733,\n 0.3607047227330512,\n 0.3607047227330512,\n 0.36064074928215234,\n 0.36035452363295134,\n 0.36030256317446885,\n 0.360299916481862,\n 0.360142132704171,\n 0.3599026188839901,\n 0.35989793516521495,\n 0.35989793516521495,\n 0.35949080821540397,\n 0.35949080821540397,\n 0.35949080821540397,\n 0.3592513039379866,\n 0.359081151266729,\n 0.359081151266729,\n 0.359081151266729,\n 0.359081151266729,\n 0.359081151266729,\n 0.359081151266729,\n 0.35890208342969143,\n 0.35890208342969143,\n 0.35877732382452004,\n 0.3587247708229544,\n 0.35869256178341224,\n 0.3586347601576191,\n 0.3583271599387173,\n 0.3582541202116996,\n 0.3582541202116996,\n 0.3582541202116996,\n 0.3582541202116996,\n 0.3581939964208428,\n 0.3578786902910619,\n 0.3578366810164116,\n 0.3576589118285116,\n 0.3576371154532283,\n 0.35748774617938056,\n 0.35741658161365153,\n 0.35741658161365153,\n 0.35735013080979466,\n 0.35699378788053343,\n 0.35699378788053343,\n 0.3569360788869313,\n 0.35673210883826734,\n 0.35673210883826734,\n 0.3565682650333819,\n 0.3561853804234274,\n 0.35613997761055943,\n 0.35601487973820334,\n 0.3557088894547328,\n 0.3556370234926666,\n 0.3554740330430764,\n 0.3554740330430764,\n 0.35527496369455486,\n 0.35527496369455486,\n 0.3552686754464796,\n 0.3549163026849795,\n 0.3549163026849795,\n 0.35491147023786,\n 0.3548737035898176,\n 0.3548381627257406,\n 0.3544763499231776,\n 0.35439844819151123,\n 0.35439844819151123,\n 0.3543538111199551,\n 0.35434731201070346,\n 0.35419147870261003,\n 0.35419147870261003,\n 0.35405496711197265,\n 0.3539557809623815,\n 0.3539557809623815,\n 0.35394464889923755,\n 0.3537892072421586,\n 0.3535890259080893,\n 0.3535423787446192,\n 0.353510121115265,\n 0.353510121115265,\n 0.353510121115265,\n 0.353510121115265,\n 0.35327948127366793,\n 0.35327862217114236,\n 0.3532142141686384,\n 0.3530614279118667,\n 0.3530614279118667,\n 0.3530614279118667,\n 0.3530614279118667,\n 0.35303765446980345,\n 0.35302040901270704,\n 0.35291831679394314,\n 0.3529083479915904,\n 0.3526369382621597,\n 0.35262547475805794,\n 0.3526096597763363,\n 0.3526096597763363,\n 0.3526096597763363,\n 0.3526096597763363,\n 0.3523184028574015,\n 0.35222223455148327,\n 0.3521547742721503,\n 0.3521547742721503,\n 0.352054760236714,\n 0.3518652608625934,\n 0.35169672807819063,\n 0.35169672807819063,\n 0.3515208154883415,\n 0.35146698821668815,\n 0.35146698821668815,\n 0.3514315902923188,\n 0.3513670549743256,\n 0.3512354769639865,\n 0.3512354769639865,\n 0.35121305921314866,\n 0.3505457887394203,\n 0.350522295510383,\n 0.35044813947811776,\n 0.3503048490475368,\n 0.35030317835150665,\n 0.35030317835150665,\n 0.35010411824680177,\n 0.3498320376102666,\n 0.3498320376102666,\n 0.3498320376102666,\n 0.34982131026111674,\n 0.34935750540688765,\n 0.34935750540688765,\n 0.34935750540688765,\n 0.34935750540688765,\n 0.34935750540688765,\n 0.34935750540688765,\n 0.3491343950109765,\n 0.348879532560895,\n 0.348879532560895,\n 0.34873242517776337,\n 0.3483980688142275,\n 0.34792105671982465,\n 0.3479130627995251,\n 0.3479130627995251,\n 0.3479130627995251,\n 0.3479130627995251,\n 0.3479130627995251,\n 0.3479130627995251,\n 0.3474244620072402,\n 0.34739980079735927,\n 0.3473890247159611,\n 0.3473745428124707,\n 0.3470803284224769,\n 0.34695680560127684,\n 0.3469322127515222,\n 0.3469322127515222,\n 0.3469322127515222,\n 0.3464362601348175,\n 0.3464362601348175,\n 0.3461259930142526,\n 0.3459657399108972,\n 0.3459365480111287,\n 0.3459365480111287,\n 0.3459365480111287,\n 0.3459365480111287,\n 0.34549539162083404,\n 0.3454330189478702,\n 0.3454330189478702,\n 0.34541719835176615,\n 0.3451622777137104,\n 0.3449999451135949,\n 0.3449256141862555,\n 0.3449256141862555,\n 0.3449256141862555,\n 0.3449256141862555,\n 0.34482804849875287,\n 0.3447770682501871,\n 0.34471487269475243,\n 0.3445002564541144,\n 0.3444440976299315,\n 0.34442778157001885,\n 0.34441427360014865,\n 0.34421636863455163,\n 0.3440913748097045,\n 0.3438989356533071,\n 0.3438989356533071,\n 0.3438665809723832,\n 0.34359364201002734,\n 0.343536509772295,\n 0.34337953735494,\n 0.34337953735494,\n 0.34337953735494,\n 0.34318038745049784,\n 0.3430204279011441,\n 0.3429251516903207,\n 0.3428560142135018,\n 0.3428560142135018,\n 0.3428560142135018,\n 0.3428560142135018,\n 0.34273207540636696,\n 0.34273207540636696,\n 0.3426467620463074,\n 0.3423283001886365,\n 0.3423283001886365,\n 0.3423283001886365,\n 0.3423283001886365,\n 0.3420547426217531,\n 0.3417963276411828,\n 0.3417963276411828,\n 0.34149838624559825,\n 0.34141987129906276,\n 0.34131008668142626,\n 0.3412600272811451,\n 0.3412600272811451,\n 0.3412600272811451,\n 0.3410956578728549,\n 0.3407340392731483,\n 0.3407193281135319,\n 0.3407193281135319,\n 0.3407193281135319,\n 0.34066473200451686,\n 0.34066473200451686,\n 0.34047905239821824,\n 0.3403632114458081,\n 0.34019121626044924,\n 0.34017415738195345,\n 0.34017415738195345,\n 0.34017415738195345,\n 0.34017415738195345,\n 0.34017415738195345,\n 0.33962444050986773,\n 0.33962444050986773,\n 0.3395438713245851,\n 0.3394759319430426,\n 0.3390701010393569,\n 0.3390701010393569,\n 0.3390701010393569,\n 0.3390701010393569,\n 0.3390701010393569,\n 0.33858844340790273,\n 0.33856344281709244,\n 0.33855951257091466,\n 0.3380305617539328,\n 0.33794723867885806,\n 0.33794723867885806,\n 0.33794723867885806,\n 0.33794723867885806,\n 0.33794723867885806,\n 0.33794723867885806,\n 0.33794723867885806,\n 0.33794723867885806,\n 0.33794723867885806,\n 0.33794723867885806,\n 0.33794723867885806,\n 0.33794723867885806,\n 0.3378376505192268,\n 0.3377750509746819,\n 0.3376732515956884,\n 0.3376290740109894,\n 0.3373785528779849,\n 0.3373785528779849,\n 0.3373785528779849,\n 0.3373785528779849,\n 0.33735794426673144,\n 0.3372104304333807,\n 0.3370035805858675,\n 0.336804918515056,\n 0.336804918515056,\n 0.336804918515056,\n 0.336804918515056,\n 0.336804918515056,\n 0.336804918515056,\n 0.33675942892410643,\n 0.33663649588821914,\n 0.3364304106765685,\n 0.3362262487112137,\n 0.3362262487112137,\n 0.3362262487112137,\n 0.3362262487112137,\n 0.3362262487112137,\n 0.3362262487112137,\n 0.3362262487112137,\n 0.33611193499510195,\n 0.33578481694515155,\n 0.33576913207734504,\n 0.3356424542794056,\n 0.3356424542794056,\n 0.3356424542794056,\n 0.3356424542794056,\n 0.33547741847384993,\n 0.3354076476063448,\n 0.33538360317162863,\n 0.3353233000208412,\n 0.3352965190692345,\n 0.3352014651071032,\n 0.33519123750334456,\n 0.33519123750334456,\n 0.3351217224031652,\n 0.3350534436418883,\n 0.3350534436418883,\n 0.3350534436418883,\n 0.3348734244930876,\n 0.33478308967221754,\n 0.33476323158437693,\n 0.3346254573990321,\n 0.3345606011542046,\n 0.3344591227440117,\n 0.3344591227440117,\n 0.3344591227440117,\n 0.3344591227440117,\n 0.3344591227440117,\n 0.3344312945855564,\n 0.3344312945855564,\n 0.3342903996448128,\n 0.3342292171532705,\n 0.3340883263653059,\n 0.3340389446859438,\n 0.33393140586495645,\n 0.33385939496408196,\n 0.33385939496408196,\n 0.3338202241422576,\n 0.3337028116834172,\n 0.3337021723955966,\n 0.3336624828311519,\n 0.3336624828311519,\n 0.3335331388775244,\n 0.333398717608863,\n 0.3333571717808336,\n 0.33327877313876103,\n 0.33327834789122984,\n 0.33325416101908617,\n 0.33325416101908617,\n 0.33325416101908617,\n 0.33325416101908617,\n 0.33317699741719936,\n 0.33288459270673576,\n 0.3328506341393888,\n 0.3326433188660496,\n 0.3326433188660496,\n 0.3326433188660496,\n 0.3326433188660496,\n 0.332509733421612,\n 0.33225138017233596,\n 0.3321811436181807,\n 0.332026763598779,\n 0.332026763598779,\n 0.332026763598779,\n 0.332026763598779,\n 0.332026763598779,\n 0.33197362852474493,\n 0.33140438733973215,\n 0.3313287962214863,\n 0.3313007012706088,\n 0.3313007012706088,\n 0.3311140386818244,\n 0.3311008751302735,\n 0.3310365390812319,\n 0.33082141310959895,\n 0.33077607912673423,\n 0.33077607912673423,\n 0.33077607912673423,\n 0.33077607912673423,\n 0.3307679395362336,\n 0.3306601906164306,\n 0.3302625254119081,\n 0.3301831422913184,\n 0.3301472738049542,\n 0.33014172479424286,\n 0.33014172479424286,\n 0.33014172479424286,\n 0.33014172479424286,\n 0.33014172479424286,\n 0.33014172479424286,\n 0.33014172479424286,\n 0.33013088381555455,\n 0.3300480232256475,\n 0.3296777869837063,\n 0.3295012068488451,\n 0.3295012068488451,\n 0.3294417072854001,\n 0.32932992870214167,\n 0.32923542274198203,\n 0.3288544043386466,\n 0.3288544043386466,\n 0.3288544043386466,\n 0.3288544043386466,\n 0.3288544043386466,\n 0.3288544043386466,\n 0.3288544043386466,\n 0.32861202247920457,\n 0.32861202247920457,\n 0.32861202247920457,\n 0.32861202247920457,\n 0.32853643333314037,\n 0.3283319460530703,\n 0.32820119271618864,\n 0.32820119271618864,\n 0.32820119271618864,\n 0.32820119271618864,\n 0.32820119271618864,\n 0.32812830784452,\n 0.32800750488113556,\n 0.3279565894238303,\n 0.3277717542322812,\n 0.32765904011409497,\n 0.3275414436945058,\n 0.3275414436945058,\n 0.3275414436945058,\n 0.3275414436945058,\n 0.32742721449887596,\n 0.3273591997947729,\n 0.32732611693995745,\n 0.32697028125418864,\n 0.32692843543974803,\n 0.3269211415178784,\n 0.3269206289359994,\n 0.3269025747847511,\n 0.3268750250959079,\n 0.3268750250959079,\n 0.3268750250959079,\n 0.3268750250959079,\n 0.3267554080607024,\n 0.32667446076084633,\n 0.32657804500137133,\n 0.3265598268366451,\n 0.326539098811351,\n 0.3264859140601529,\n 0.32645016094854834,\n 0.3262018006930394,\n 0.3262018006930394,\n 0.3262018006930394,\n ...)"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}